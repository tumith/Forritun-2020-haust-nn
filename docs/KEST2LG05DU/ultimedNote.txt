"""

MEANING OF THINGS

	!!! = important

	!!!! = Warnings

	# = command or just comments

	## = interesting

	### = options

	in terminal = in linux terminal

	{} = contents of a specific thing

	syntax = syntax

"""

### -r = is most often recursiv


chapter 1{
	key terms{
		
		bash
			Bourne Again SHell - an sh-compatible command language interpreter that executes commands read from the standard input or from a file.
			Section 1.3.1 
		ls
			Command that will list information about files. The current directory is listed by default.
			Section 1.3.1 

	}
}

chapter 2{
	uname{

		Short Option 			Long Option 			Prints
		-a			 	--all 				All information
		-s 				--kernel-name  			Kernel name
		-n 				--node-name 			Network node name
		-r 				--kernel-release 		Kernel release
		-v 				--kernel-version 		Kernel version
		-m 				--machine 			Machine hardware name
		-p 				--processor 			Processor type or unknown
		-i 				--hardware-platform 		Hardware platform or unknown
		-o 				--operating-system 		Operating system
						--help 				Help information
						--version 			Version information
	}

	man{
		Command 			Function
		Return (or Enter) 		Go down one line
		Space 				Go down one page
		/term 				Search for term
		n 				Find next search item
		1G 				Go to the beginning of the page
		G 				Go to the end of the page
		h 				Display help
		q 				Quit man page
	}

	key terms{
		
		Quoting
			Enclosing special characters in quotes will prevent the shell from interpreting special characters. Double quotes will prevent the shell from interpreting some of these special characters; single quotes prevent the shell from interpreting any special characters.
			Section 2.3.1.1 
		echo
			Echo the STRING(s) to standard output. Useful with scripts.
			Section 2.3.1.1 
		man
			An interface to the on-line reference manuals.
			Section 2.9 | Section 2.9.1 | Section 2.9.2 | Section 2.9.3 | Section 2.9.4 | Section 2.9.5 | Section 2.9.6 | Section 2.9.6.1 | Section 2.9.6.2 | Section 2.9.6.3 | Section 2.9.6.4 
		pwd
			Print the name of the current working directory.
			Section 2.6 
		uname
			Print certain system information such as kernel name, network node hostname, kernel release, kernel version, machine hardware name, processor type, hardware platform, and operating system, depending on options provided.
			Section 2.5 

	}
}

chapter 3{
	key terms{
		
		.bash_history
			File used to store the current history list when the shell is closed.
			Section 3.4 
		env
			Print a list of the current Environment variables or change to an alternate environment.
			Section 3.2.1 
		export
			Makes an assigned variable available to sub-processes.
			Section 3.2.1 
		history
			Print a list of previously executed commands or "re-execute" previously executed commands.
			Section 3.4 
		set
			Display all variables (local and environment).
			Section 3.2.2 
		unset
			Remove one or more variables.
			Section 3.2.3 

	}
}

chapter 4{
	key terms{
		
		file globbing
			The glob function searches for all the pathnames matching pattern according to the rules used by the shell. ( * , ? , [] , )
			Section 4.1 | Section 4.2 | Section 4.3 | Section 4.4 

	}
}

chapter 5{
	key terms{

		cp
			Command used to copy files and directories. cp will copy a SOURCE to a DEST, or multiple SOURCES to a DIRECTORY.
			Section 5.5 
		file
			Command used to determine the type of file. file tests each argument in an attempt to classify it. There are three sets of tests, preformed in this order: filesystem test, magic tests, and language tests.
			Section 5.3 
		ls
			Command that will list information about files. The current directory is listed by default.
			| Section 5.2 
		mkdir
			Command used to create directories, if they do not already exist.
			Section 5.8 
		rm
			Command used to remove files or directories. By default the rm command will not remove directories.
			Section 5.7 
		rmdir
			Command that is used to remove empty directories in the filesystem.
			Section 5.9 
		touch
			Command used to change the file timestamps. touch will allow a user to update the access and modification times of each FILE to the current time.
			Section 5.4 

	}
}

chapter 6{
	key terms{
		
		/etc/updatedb.conf
			A configuration file for the updatedb utility. In some implementations, updatedb.conf is a shell script that allows more flexibility in defining variables
			Section 6.3.1 
		find
			Command used to search for files in a directory hierarchy. find searches the directory tree rooted at each given file name by evaluating the given the expression from left to right.
			Section 6.3.2 
		locate
			Command used to search for files by name. locate reads one or more databases prepared by the updatedb utility and writes file names matching at least one of the PATTERNs to standard output.
			Section 6.3.1 
		type
			Command that indicates how a name would be interpreted if used as a command. When using the type utility, the path to the command will be displayed.
			Section 6.3.5 
		updatedb
			The updatedb utility creates or updates a database to be used by the locate utility.
			Section 6.3.1 
		whereis
			Command that is used to locate source/binary and manuals sections for specified rules. This will locate binary, source, and manual pages for a command.
			Section 6.3.3 
		which
			Command that returns the pathnames of the files, or links, which would be executed in the current environment. It does this by searching the PATH for executables matching the names of the arguments.
			Section 6.3.4 

	}
}

chapter 7{
	key terms{
		
		cat
			Displays the contents of one or more files (concatenate) to standard output.
			Section 7.2 
		cut
			Command used to extract fields of information from a text file.
			Section 7.9 
		head
			Prints the first ten lines of a file by default. The number of lines can be set to any desired value.
			Section 7.5 
		less
			Pager command used to view file contents one page of data at a time.
			Section 7.2 
		nl
			Prepend a number to the lines of a file incrementing each line by 1 by default.
			Section 7.4 
		od
			Performs an octal dump of data by default. Often used to display the contents of files with non-printable characters.
			Section 7.12 
		paste
			Merge the lines of one or more files, line by line, separating the output by tabs by default.
			Section 7.7 
		sed
			A non-interactive editor that can be used to modify text.
			Section 7.14 
		sort
			Command used to display a file sorted on a specific field of data.
			Section 7.9 
		split
			Command used to take one file and break it into multiple parts. By default it breaks the file up into 1000 line sections.
			Section 7.3 
		tail
			Prints the last ten lines of a file by default. The number of lines can be set to any desired value.
			Section 7.6 
		tr
			Command used to translate one set of characters to another.
			Section 7.13 
		uniq
			Command to remove duplicate lines that are currently consecutive.
			Section 7.11 
		wc
			Print newline, word, and byte counts for each FILE, and a total line if more than one FILE is specified.
			Section 7.15 

	}
}

chapter 8{
	key terms{
		
		egrep
			Command that performs the same function as grep -E. This command has been deprecated, but is around for historical applications.
			Section 8.3 | Section 8.7 
		fgrep
			Command that performs the same function grep -F. This command has been deprecated, but is around for historical applications.
			Section 8.6 
		grep
			Command used ot print lines matching a specific pattern. grep searches the named input FILE for lines containing a match to a given PATTERN.
			Section 8.1 
		regex(7)
			Regular expression. This is a term used to describe a codified method of searching for text ,or other strings in text.
			Section 8.1 
		sed
			A non-interactive editor that can be used to modify text.
			| Section 8.4 

	}
}

chapter 9{

	# vi is a editor

	key terms{
		
		/, ?
			This is used to search for text while in command mode. the / is used to start searching. Enter a key term and press enter to begin searching the file for the text entered. If the user would like to search backwards in the document, a ? can be used instead of the /.
			Section 9.3 
		EDITOR

			Section 9.6 
		ZZ, :w!, :q!
			These keys are used to exit the vi editor from command mode. ZZ is used to save and quit the file. It must be done for each file. :w! will force the writing of the current file. :q! will exit the editor without saving changes to the current file.
			Section 9.5 
		d, p, y, dd, yy
			These are used to copy, replace and paste text when in command mode. d is used to cut one alphabetic word, where as dd is used to cut an entire line of text. y is used to copy one one alphabetic word, where as yy is used to copy and entire line at a time. If a number precedes either dd or yy, this will copy that number of lines. For example if 3dd is typed this will cut 3 lines at a time.
			Section 9.3 
		h,j,k,l
			These keys are used for basic cursor movement in vi when in command mode. h moves left one character, j moves down one line, k moves up one line, and l moves right one character.
			Section 9.2 
		i, o, a
			i, o, and a are used to enter insert mode from command mode. i will allow a user to start inserting text at the current location of the cursor. o will allow a user to start inserting text a line below the current location of the cursor, and a will allow a user to insert text one postion after the current location of the cursor.
			Section 9.4 
		vi
			A screen-oriented text editor originally created for Unix operating systems. vi is also known as a modal editor in which the user must switch modes to create, edit, and search text in a file.
			Section 9.1 | Section 9.2 | Section 9.3 | Section 9.4 | Section 9.5 

	}
}

chapter 10{
	key terms{
		
		tee
			Command used to read from standard input and write to standard output and files.
			Section 10.6 
		xargs
			Command used to build and execute command lines from standard input.
			Section 10.7 

	}
}


chapter 11{
	ps
	{ 
		ps[OPTION]...   # The ps command can be used to list processes
				# The ps command supports three styles of options{
					Traditonal UNIX style short options that use a single hyphens[-] in front of a character
					GNU style long options that use two hyphens[-] in front of a word
					BSD style options that use no hyphens[-] and single character options
				}
				# The ps command will display the processes that are running in the current terminal by default

			#ps Columns info{
				PID : The process identifier, witch is unique to the process. This info is useful to control the process by its ID number
				TTY : The name of the terminal ir pseudo-terminal where the process us running. This ifno is useful to distinguish between differebt processes that have the same name
				TIME : The total amount of processor time used by the process. Typically, this info int't used by regular users.
				CMD : The command that started the process.
			}

			# ps x [BSD option] state {
				D : Uninterruptible Sleep
				R : Running
				S : Interruptible Sleep
				T : Stopped
				Z : Zombie
			}

			# ps aux [BSD option] {
				a : Allows the ps command to show all processes
				u : Show processes by all users and ignore restrictions to only list the user's processes
				x : List all processes and remove the restriction to only display
			}# it shows everything

			in terminal{
				ps aux | grep -i sshd # To find all processes that match the sshd string
			}
	}

	pgrep
	{
		in terminal {
			pgrep -i sshd # If you wanted to find all instances of the sshd

			pgrep -li sshd # The output shows the process IDs (PID) of the processes running that match the sshd string. Additionally, the -l option can be used with the pgrep command to list the process name along with the PID

			# It is also possible to search for processes owned by a specific user by using the -u option

			pgrep -u sysadmin -l # the -u and -l options displayed the bash process which has the PID 56 and is owned by the sysadmin user.
		}

	}

	watch
	{
		syntax{ 
			watch [OPTION]... COMMAND
		}
		# The watch command can be use with date for a good test
		# The watch command can also be used with the ps command to monitor running processes in the shell
		in terminal {
			watch ps aux
		}
	}

	## To write a couple of command in one line use the semicolon [ ; ]


	Background Processes
	{
		COMMAND & 
		
		in terminal{
			sleep 3 & # this runs in the Background
		}
	}

	kill
	{
		syntax of kill command{
			kill [OPTION]... <pid>
		}

		### specifying signals for kill command {
			-<signal>
			-s <signal>
			--signal <signal>

			example for interrupt signal{
				-2
				-INT
				-SIGINT
			}
		}


		in terminal{
			kill -l # To see a list of all of the signals available for your system
 		}
		

		common signals{
			number : full name : short name : purpose
			1      : SIGHUB    :  HUP       : Hang up, usually ends a process
			2      : SIGINT    :  INT       : Interrupt, usually ends a process
			3      : SIGQUIT   :  QUIT      : Quit, usually ends a process
			9      : SIGKILL   :  KILL      : Kill, forcefully ends a process
			15     : SIGTERM   :  TERM      : Terminate, usually ends a process
			18     : SIGCONT   :  CONT      : Continue, resumes a stopped process
			19     : SIGSTOP   :  STOP      : Stop, forcefully stops a process
			20     : SIGTSTP   :  TSTP      : Terminal Stop, usually stops a process
		}
	}
	
	pkill{
		syntax{
			pkill [OPTION]... PATTERN
		}
		
		# the pkill command allows users to specify a pattern that matches a process name and then sends signals to that process
	}
	
	killall{
		syntax{
			killall [OPTION]... NAME
		}

		in terminal{
			killall sleep
		}

		# The killall command can also be used to terminate one or more processes by name and other criteria such as the user owner of the process and system processes.
	}

	# top is like the task manager

	key terms{ 
		&
			When used with a process will immediately background the process or task in a terminal. This will allow the terminal to be freed up for additional tasks.
			Section 11.2.6 

		bg
			A job control command that resumes the execution of a suspended process without bringing it to the foreground.
			Section 11.2.7 

		fg
			A job control command that resumes execution of a suspended process by bringing it to the foreground.
			Section 11.2.7 

		free
			Command used to display the amount of free and used memory in the system. This utility will display both the physical and swap memore on the system as well as the buffers used by the kernel.
			Section 11.2.3 | Section 11.3 

		jobs
			Command that lists all active jobs in the current terminal or shell.
			Section 11.2.6 

		kill
			Command used to terminate a process. There are specific signals that can terminate a process in different ways. If no signal is provided the TERM signal will be sent to the process.
			Section 11.2.8 

		killall
			Command similar to kill, but killall will allow a user to terminate a process by name as opposed to ID.
			Section 11.2.8 

		nice
			Command used to change the priority of a process. The higher the nice value the lower the priority of a process. Nice values range from -20 to 20.
			Section 11.2.10 

		nohup
			Command used to run a command immune to hangups, with output to a non-tty. If standard input is a terminal, it can be redirected from /dev/null. If standard output is the terminal, append the ouptput to nohup.out. This should be located in the user's home directory.
			Section 11.2.9 

		pgrep
			Command that parses through the running processes and looks for the specified names or other criteria of processes.
			Section 11.2.2 

		pkill
			Sends a specified signal (SIGTERM by default) to each process instead of listing them on stdout.
			Section 11.2.8 

		ps
			Command used to report a snapshot of the current processes. Different options are available with ps to report more specific information.
			Section 11.2.1 

		renice
			Command used to change the priority of a process while that process is running. The higher the value the lower the priority.
			Section 11.2.10 

		screen
			A full-screen software program that can be used to multiplex a physical console between several processes (typically interactive shells). It offers a user to open several separate terminal instances inside a one single terminal window manager. The screen application is very useful, if you are dealing with multiple programs from a command line interface and for separating programs from the terminal shell. It also allows you to share your sessions with others users and detach/attach terminal sessions.
			Section 11.4.1 

		tmux

			Section 11.4.2 

		top
			Command similar to ps, however top will display the curent real-time view of all running tasks and processes.
			Section 11.2.11 

		uptime
			Command that will display how long a system has been running. uptime gives a one line display showing the current time, how long ths system has been running, how many users are logged in, and the system load averages for the pas 1, 5 and 15 minutes.
			Section 11.3 
			
		watch

			Section 11.2.3 
	}

}


chapter 12{
	# Archiving: Combines multiple files into one, which eliminates the overhead in individual files and makes it easier to transmit.

	#Compression: Makes the files smaller by removing redundant information
	
	gzip and gunzip{
		# The gzip command is used to create a compressed file. Likewise, the gunzip command is used to view the contents of a compressed file, as well as extract those contents.
		
		syntax{
			gzip [OPTION]... [FILE]...
			gunzip [OPTION]... [FILE]...
		}

		# gzip2 compresses
		# gunzip2 uncompresses

		!!! The gzip command should be used with caution since its default behavior is to replace the original file specified with a compressed version.
	}

	zcat{
		# The zcat command is used to display the contents of a compressed file without actually uncompressing it

		syntax{
			zcat [OPTION]... [FILE]...
		}
	}

	bzip2 and bunzip2{
		#The bzip2 and bunzip2 commands work in a nearly identical fashion to the gzip and gunzip commands. However, while the gzip command uses the Lempel-Ziv data compression algorithm, the bzip utilities use a different compression algorithm called Burrows-Wheeler block sorting, that can compress files smaller than gzip at the expense of more CPU time
	
		syntax{
			bzip2 [OPTION]... [FILE]...
			bunzip2 [OPTION]... [FILE]...
		}

		# bzip2 compresses
		# bunzip2 uncompresses

		!!! The bzip2 command should be used with caution since its default behavior is to replace the original file specified with a compressed version.

		!!! ### -r recursion dose not work with bzip2 and bunzip2

		### The -v option gives a verbose output so you can see how the file was processed
	}

	bzcat{
		# The bzcat command prints the content of specified files compressed with the bzip2 command to the standard output.

		syntax{
			bzcat [OPTION]... [FILE]...
		}
	}

	xz and unxz{
		# Another archival tool similar to gzip and bzip2 is the xz command.
		### To compress a group of files individually, use the xz command with the -z option. Compression is the default operation mode, and therefore if the xz command is run with no options, the -z option is implied.

		syntax{
			xz [OPTION]... [FILE]...
		}

		### The -d option can be used with the xz command to uncompress the files just as easily

		# Another method of uncompressing files compressed using the xz command is to use the unxz command. Using unxz to uncompress a file is very similar to using gunzip because it uses similar syntax.
	
		!!! There are a huge number of options for the xz command, some relating to the compression ratio. Keep in mind when using xz that the more aggressive the compression, the harder the processor will have to work.
	}

	xzcat{
		# The xzcat command is used to print the contents of files compressed with the xz command to standard output on the terminal without uncompressing the target file.

		syntax{
			xzcat [FILE]...
		}
	}

	tar{
		## The tar command is typically used to make archives within Linux. These tar archive files, sometimes called tarballs, were originally used to backup data onto magnetic tape. Tar is derived from the words "tape archive".

		# While the primary purpose of the tar command is to merge multiple files into a single file, it is capable of many different operations, and there are numerous options

			tar functionalitys{
				
				### Create = -c # Make a new archive out of a series of files.

				### Extract = -x # Pull one or more files out of an archive.

				### List = -t # Show the contents of the archive without extracting.

			}

		Create Mode{

			syntax{
				tar -c [-f ARCHIVE] [OPTIONS] [FILE...]
			}

			### -c = create an archive.
			
			### -f ARCHIVE = Use the ARCHIVE file. The argument ARCHIVE will be the name of the resulting archive file.

			## All the remaining arguments, [FILE…], are considered as input file names either as a list of files, as a wildcard, or both.

			in terminal{
				tar -cf mydocuments.tar ~/Documents
			}
			
			### -v = Verbosely list the files processed.
			
			### -z = Compress (or decompress) the archive using the gzip command.

			### -j = Filter the archive through the bzip2 command

			### -J = Filter the archive through the xz command.

			## File extensions are not relevant to Linux; however, it is customary to add .tar.gz to the name of the compressed archive. 

			in terminal{
				tar -cvzf mydocuments.tar.gz ~/Documents
			}

		}

		List Mode{
			
			syntax{
				tar -t [-f ARCHIVE] [OPTIONS]
			}

			### -t = List the files in the archive. (table of contents)

			### -f ARCHIVE = Operate on the given archive. 

			in terminal{
				tar -tf mydocuments.tar.gz
			}

			## note that the -f option is used last so that the file name can be specified as an argument to this option

			in terminal{
				# you can add the verbose (-v) to get a more detailed output

				tar -tvf mydocuments.tar.gz
			}

		}

		Extract Mode{

			syntax{
				tar -x [-f ARCHIVE] [OPTIONS]
			}

			### -x = Extract files from an archive.

			### -f ARCHIVE = Operate on the given archive.

		}
	}

	zip and unzip{

		syntax{
			zip [OPTIONS]... [FILE]...
		}

		### One especially useful option for the zip command is the -r option, which allows the zip command to recursively compress

		# The unzip command is used to extract the files from the zip archive file. Use the unzip command without options to extract a zip archive

		### To view the contents of a zip file without unpacking it, use the unzip command with the list -l option:
	}

	cpio{
		## In copy-out mode, the cpio command will copy files from a directory into an archive.

		## In copy-out mode, the cpio command will copy files from a directory into an archive.

		## There is a third mode called the copy-pass mode. In this mode, the cpio command copies files from one directory to another, which combines the copy-out and copy-in modes without creating an archive file.
	
		Copy-Out Mode{
			### The -o option puts the cpio command into copy-out mode

			### Using the verbose -v option will cause the cpio command to list the files that it processes

			in terminal {
				ls | cpio -ov > archive.cpio
			}

			find command{

				in terminal{
					find . -depth -print | cpio -vo > /tmp/ar.cpio
				}

			}
		}

		Copy-In Mode{

			### To extract the files that are in a cpio archive, use the -i option with the cpio command to specify copy-in mode

			### By default, cpio will not overwrite existing files unless the -u option is used.

			!!! ### The cpio command will not create directories unless the -d option is used.

			in terminal{

				cpio -idv /tmp/test < /tmp/ar.cpio

				find ~ | cpio -pd /tmp/destination

			}

			## To specify the pass-through mode of the cpio command, specify the -p option. Again, if any directories are included, the -d option needs to be specified

			## To prevent problems with files that have white space characters (like the spacebar character) embedded in them, specify the -print0 option to the find command

			## For the cpio command to process the list of null separated files, add the --null option. This results in a more robust version of the previous pass-through command

			in terminal{
				find . -print0 | cpio --null -pvd /tmp/destination
			}

		}
	}

	dd{
		# The dd command is a utility for copying files or entire partitions at the bit level

		dd features{
			
			It can be used to clone or delete (wipe) entire disks or partitions.
			
			It can be used to copy raw data to removable devices, such as USB drives and CDROMs.
			
			It can backup and restore the MBR (Master Boot Record), a critical software component that is used to boot the system.
			
			It can be used to create a file of a specific size that is filled with binary zeros, which can then be used as a swap file (virtual memory).

		}

		dd commonly used special arguments{
			if=FILE : The input file to be read.
			of=FILE : The output file to be written.
			bs=SIZE : The block size to be used. By default, the value is considered to be in bytes. Use the following suffixes to specify other units: K, M, G, and T for kilobytes, megabytes, gigabytes, and terabytes respectively.
			count=NUMBERS : The number of blocks to read from the input file.
		}

		in terminal{
			# In the following example, a file named /tmp/swapex is created with 500 "one-megabyte" size blocks of zeros:

			dd if=/dev/zero of=/tmp/swapex bs=1M count=500
		}

	}

	key terms{
		
		bunzip2
			Command that uncompresses files compressed using the <command>bzip2</command> command and removes the .bz2 extension.
			Section 12.4 
		bzcat
			Command prints the content of specified files compressed with the <command>bzip2</command> command to the standard output.
			Section 12.5 
		gunzip
			Command that decompress files created by gzip, zip, compress, compress -H or pack.
			Section 12.2 
		gzip
			Command used to comperess or expand files. Gzip reduces the size of the named files using Lempel-Ziv coding (LZ77). Whenever possible, each file is replaced by one with the extension .gz, while keeping the same ownership modes, access and modification times. (The default extension is -gz for VMS, z for MSDOS, OS/2 FAT, Windows NT FAT and Atari.)
			Section 12.2 
		unxz
			A method of uncompressing files compressed using the <command>xz</command> command.
			Section 12.6 
		xz
			Command that can compress or decompress .zx or .lzma files. xz is a general-purpose data compression tool with command line syntax similar to gzip(1) and bzip2(1). The native file format is the .xz format, but also the legacy .lzma format and raw compressed streams with no container format headers are supported.
			Section 12.6 
		xzcat
			Command used to print the contents of files compressed with the <command>xz</command> command to standard output on the terminal without uncompressing the target file.
			Section 12.7 
		zcat
			Command used to display the contents of a compressed file from a compressed archive created by the <command>tar</command> or <command>gzip</command> commands without uncompressing it. Its effect is identical to running the <command>gzip -c</command> command:
			Section 12.3 

	}
}



chapter 13 and 14{

	File Type Field{
		-rwxr-xr-x. 1 root root 133792 Jan  18  2018 /bin/ls
		^
	}

	Permissions Field{
		-rwxr-xr-x. 1 root root 133792 Jan  18  2018 /bin/ls
		 ^^^^^^^^^
	}

	User Owner Field{
		-rwxr-xr-x. 1 root root 133792 Jan  18  2018 /bin/ls
			      ^^^^
	}

	Group Owner Field{
		-rwxr-xr-x. 1 root root 133792 Jan  18  2018 /bin/ls
				   ^^^^
	}

	Switching Users{
		
		!!! ## By default, if a username is not specified, the su command opens a new shell as the root user. The following two commands are equivalent ways to start a shell as the root user:

		syntax{
			su [OPTIONS] [USERNAME]
		}

		login shell{
			# When switching users, utilizing the login shell option is recommended as the login shell fully configures the new shell with the settings of the new user, ensuring any commands executed run correctly. If this option is omitted, the new shell changes the UID but doesn't fully log in as the user
		
			The login shell option can be specified one of three ways:{

				in terminal{

					su -
					su -l
					su --login

				}

			}
		}

		sudo{
			
			syntax{
				sudo [OPTIONS] COMMAND
			}

		}
	}

	Changing File User Owner{

		## Initially, the owner of a file is the user who creates it. The user owner can only be changed by a user with root privileges using the chown command

		syntax{
			chown [OPTION]... [OWNER] FILE..
		}
	}

	Switching Groups{
		## To create a file or directory that will be owned by a group different from your current primary group, one option is to change your current primary group to another group you belong to by using the newgrp command.

		syntax{
			newgrp [GROUP]
		}

		## Once in the new shell, any file created, in this case, newfile.txt, will belong to the new primary group
	}

	Changing File Group Owner{

		## Another option is for the user owner of the file to change the group owner by using the chgrp command. For example, if you forgot to use the newgrp command to switch to the user’s primary group before creating the file.
	}

	chmod{
		symbol method{
			
			# + = - u = user, g = group, o = other, a = all

			# r = read
			# w = write
			# x = execute

		}

		in terminal {
			touch permissions.txt

			chmod g-r permissions.txt # minus read from group
			chmod g+r permissions.txt # add read to group

			chmod u+w permissions.txt # add write to user

			chmod o=w,g-r,u+x permissions.txt # other = write, group - read, user add execute

			chmod a=- permissions.txt # clear all permissions
		} 
		octal method{
			
			read( r ) = 4
			write( w ) = 2
			execute( x ) = 1
			none = 0
			
		}

		in terminal{
			chmod 765 permissions.txt # adding read, write and execute

			chmod 000 permissions.txt # clear all permissions

			# chmod user,group,other permissions.txt
		}


		more about octal method{
			7 : rwx
			6 : rw-
			5 : r-x
			4 : r--
			3 : -wx
			2 : -w-
			1 : --x
			0 : ---
		}

		setuid{
			# When the setuid permission is set on an executable binary file (a program), the binary file is run as the owner of the file, not as the user who executed it. This permission is set on a handful of system utilities so that they can be run by normal users, but executed with the permissions of root, providing access to system files that the normal user doesn't normally have access to.

			in terminal symbolically{

				add{
					chmod u+s file
				}

				remove{
					chmod u-s file
				}

			}

			in terminal octal{
				
				add{
					chmod 4000 file
				}

				remove{
					chmod 0000 file
				}
			}

			## Permission with the octal method using three-digit codes. When a three-digit code is provided, the chmod command assumes that the first digit before the three-digit code is 0. Only when four digits are specified is a special permission set.
			## If three digits are specified when changing the permissions on a file that already has a special permission set, the first digit will be set to 0, and the special permission will be removed from the file.
		}

		setgid{
			# The setgid permission is similar to setuid, but it makes use of the group owner permissions. There are two forms of setgid permissions: setgid on a file and setgid on a directory. The behavior of setgid depends on whether it is set on a file or directory.
			# The setgid permission on a file works very similarly to the setuid permission, except that instead of executing as the user who owns the file, setgid permission will execute as the group that owns the file. The system allows the user running the command to effectively belong to the group that owns the file, but only in the setgid program.
		
			in terminal symbolically{
				
				add{
					chmod g+s <file|directory>
				}

				remove{
					chmod g-s <file|directory>
				}
			}

			in terminal octal{
				
				add{
					chmod 2000 <file|directory>
				}

				remove{
					chmod 0000 <file|directory>
				}
			}

		}

		Sticky Bit{
			# Setting this permission can be important to prevent users from deleting other user's files.

			in terminal symbolically{
				
				add{
					chmod o+t <directory>
				}
				
				remove{
					chmod o-t <directory>
				}
			}

			in terminal octal{
				
				add{
					chmod 1000 <file|directory>
				}

				remove{
					chmod 0000 <file|directory>
				}
			}
		}

		special Sticky + setgid{
			
			in terminal{
				chmod 3770 <file>

				output{
					drwxrws--T. 2 <user> <group> 4096 Jan 10 09:08 <file>
				}
			}

			## Notice that the special permissions of setgid and sticky bit can be added together, the 2000 permission plus the 1000 permission gives you 3000 for the special permissions. Add this to the basic permissions for the user, group, and others; The owner and group have full access, and others get none.
		
			## The uppercase T in the execute permission position for others indicates there is no execute permission for others. However, since multiple users of the group still have access, the sticky permission is effective for the group.
		}
	}

	key terms for chapter 13{
		
		chgrp
			Command that is used to change the primary group of a file. Essentially it changes what group is the owner of the FILE.
			Section 13.2.4 
		chmod
			Command that is used to change the mode bits of a FILE. The chmod utility can be used to change the files permissions. For example setting the read, write, and execute bits.
			Section 13.4 
		chown
			Command that is used to change the ownership of a FILE. The chown utility can also be used to change the primary group of a FILE as well.
			Section 13.2.2 
		umask
			Command that sets the calling process's file mode creation mask. The umask utility will set the default permissions for FILEs when they are created.
			Section 13.7 


	}

	-------------- chapter 14 begining ----------------------------------------------------------------------------------------------------------------------------------------------

	users{
		sudo adduser **name** # create user

		cat /etc/passwd | grep ^**name** # to loced user
	}

	df -i # Inodes table


	links{
		in terminal{
			touch file.txt file1.txt
		}

		hardlink{
			
			syntax{
				ln TARGET LINK_NAME
				## To create hard links, the ln command is used with two arguments (and without the -s option). The first argument is an existing file name to link to, called a target, and the second argument is the new file name to link to the target.
			}

			in terminal{
				ln file.txt hardlink_to_file.txt # using hardlink to link to file.txt
			}

			filename, incode{
				passwd : 123
				shadow : 175
				group : 144
				gshadow : 897
			}

		}

		softlinks{
			
			syntax{
				ln -s TARGET LINK_NAME
			}

			in terminal{
				ln -s file1.txt symlink_to_file1.txt # -s for softlinks this is a symbolicklink, Softlinks(symbolicklinks) can be used like shortcuts linking a file to another file
			}

		}


		ls -li # see everything with Inodes numbers
	}
}


chapter 15{
	in class{ 
		chapter 15: hardware configuration

			1- Core hardware

			CPU central processing unit

			Ram randon access memory

			Storage like hard drives, CDROMs, and DVDs

			Display and keyboard



			2- generating CPU info

			lscpu //informatino about cpu

			uname -m //cpu architecture

			cat /proc/cpuinfo //displays information about the cpu



			3- Generating Memory info



			cat /proc/meminfo

			free



			4- Generating hard disk info

			df -h

			sudo fdisk -l



			5- generaing PCI and USB info

			lspci

			lsusb



			6- inserting, removing and updating Modules in Linux

			sudo lsmod // list all the modules

			sudo modinfo <Module Name>

			sudo rmmod <path to the module>

			sudo insmod <path of the module>
	}

	me read{

		Central Processing Unit{ 
			## The central processing unit (CPU) is the brain of the computer, where the instructions to perform calculations or manipulate data are processed. There are numerous types of CPUs that are able to work with Linux, but the most common is the 64-bit x86_64 type, and decreasingly, the 32-bit x86 type. Both of these types of CPUs are backward compatible with the CPU used in the first IBM Personal Computer (PC), the Intel 8088 CPU.

			uname{
				Information 		Option 		Example
				Kernel name 		-s 			Linux
				Nodename 			-n 			localhost
				Kernel release 		-r 			4.4.0-72-generic
				Kernel version 		-v 			#93~14.04.1-Ubuntu SMP Fri Mar 31 15:05:15 UTC 2017
				Machine hardware 	-m 			x86_64
				Processor 			-p 			x86_64
				Hardware platform 	-i 			x86_64
				Operating System 	-o 			GNU/Linux
			}
		}

		Random Access Memory{
		
			Consider This

			Unit 			Abbreviation 	Value (Bytes)
			kibibyte 		KiB 			1024
			mebibyte 		MiB 			10242 = 1,048,576
			gibibyte 		GiB 			10243 = 1,073,741,824
			tebibyte 		TiB 			10244 = 1,099,511,627,776
			exbibyte 		EiB 			10246 = 1,152,921,504,606,846,976

			A typical desktop in the year 2019 has 16 GiB of RAM. That is more than 26000 times the amount of RAM in a fully loaded IBM PC in the year 1981!

			in terminal{
				cat /proc/meminfo

				output{
					MemTotal:       132014640 kB
					MemFree:         67439868 kB
					MemAvailable:    99487364 kB
					Buffers:          2116936 kB
					Cached:          27429740 kB
					SwapCached:            40 kB
					Active:          14409408 kB
					Inactive:        23724500 kB
					Active(anon):     8400252 kB
					Inactive(anon):    191680 kB
					Active(file):     6009156 kB
					Inactive(file):  23532820 kB
					Unevictable:            0 kB
					Mlocked:                0 kB
					SwapTotal:      134196220 kB
					SwapFree:       134195752 kB
				}
			}

			in terminal{
				free

				output{
					              total        used        free      shared  buff/cache   available
					Mem:         128920       35120       89205           2        4594       93190
					Swap:        131050         140      130910
				}
			}
		}

		Mass Storage Devices{ 
			# The Small Computer System Interface (SCSI) is one of the oldest and requires a SCSI controller in the system to control one or more disk drives that connect to it.

			# The Integrated Drive Electronics (IDE) or Parallel Advanced Technology Attachment (PATA) type interface includes the controller directly on each drive and was very popular for hard disks through the 1990s. This type is still used for some optical drive devices today.

			# The most common interface used for internal mass storage devices today is the Serial Advanced Technology Attachment (SATA) type. Each SATA drive is connected directly to the system board by a cable. To configure the primary SATA drive, connect it with a cable to the connector of the system board that is designated as the primary port.

			# For external drives, the Universal Serial Bus (USB) interface is the most common, but there are other standards such as FireWire and Thunderbolt.
		}

		Firmware{
			BIOS{
				# Originally, this firmware was known as the Basic Input/Output System (BIOS), System ROM, or ROM BIOS. BIOS is used to provide basic services, called input and output services before an operating system is loaded, so the user may provide input through the keyboard or see output on a monitor even before the bootloader or an operating system is executed.
			}

			UEFI{
				# Recently, computer manufacturers have begun to replace the traditional BIOS with something called the Unified Extensible Firmware Interface (UEFI); however, the functions of UEFI appear so similar to BIOS that many people still refer to the system firmware as BIOS.
			}

			about BIOS and UEFI{
				# Both UEFI-based systems and BIOS-based systems provide a proprietary menu program that allows integrated devices to be enabled or disabled. The firmware that is included varies with each system vendor, so, unfortunately, there is no standard way to start this program or standard menu item for enabling or disabling devices.
			}

			Secure Boot and CSM{
				‌⁠​​⁠​If a system has UEFI firmware, then it may be more challenging to boot the Linux operating system due to a feature called Secure Boot. If Secure Boot is enabled, then the bootloader must be cryptographically signed by a digital key that is recognized by the firmware. If the bootloader is not properly signed, then booting may still be possible by disabling Secure Boot in the firmware settings, in favor of the Compatibility Support Module (CSM).
			}
		}

		Hardware Resources{ 
			IO Ports{
				# Memory addresses that allow for communication with hardware devices

				in terminal{
					cat /proc/ioports

					output{
						0000-0cf7 : PCI Bus 0000:00
							0000-001f : dma1
							0020-0021 : pic1
							0040-0043 : timer0
							0050-0053 : timer1
							0060-0060 : keyboard
							0064-0064 : keyboard
					}
				}
			}

			IO Memory{
				#  A section or location that acts much like the RAM that is presented to the processor via the system bus. These are used to pass and store data as well as for access to devices on the system
				
				in terminal{
					cat /proc/iomem

					output{
						00010000-0009ffff : System RAM
						000a0000-000bffff : PCI Bus 0000:00
						000c0000-000c7fff : Video ROM
						000c8000-000cdfff : Adapter ROM
						000f0000-000fffff : System ROM
						00100000-be777fff : System RAM
							06000000-0680bdb2 : Kernel code
							0680bdb3-06f45abf : Kernel data
					}
				}
			}

			Interrupt Requests (IRQ){
				#  An interrupt is a hardware signal that pauses or stops a running program so that the interrupt handler can switch to running another program, or send and receive data. There are a set of commonly-defined interrupts called IRQ’s that map to common interfaces, such as the system timer, keyboard controller, serial and parallel ports, and floppy controllers.
			}

			Direct Memory Access (DMA){
				# A method by which particular hardware items in the system can directly access RAM, without going through the CPU. This speeds up access, as the CPU would otherwise be fully tasked during such access, making it unavailable for other tasks for the duration.

				in terminal{
					cat /proc/dma

					output{
						4: cascade
					}
				}
			}

			## Note that, with the exception of interrupt requests, these resources cannot be shared between devices. Also, keep in mind that administrators rarely need to view this data on modern Linux systems as the configuration of devices is almost always transparent and automatic.
		}

		Viewing Hardware{
			## Modern computers typically use the Peripheral Component Interconnect Express (PCIe) bus to connect components inside the computer. For example, video, sound, network, and disk controllers are normally found on the PCIe bus.
			
			## A bus is not only used to refer to actual physical connections, but also software components designed to connect programs and certain communications protocols. Components are attached with a type of bus and communicate through it at high rates of speed.
		
			internal and external bus (ISA, SCSI, USB){
				Buses can be alternatively grouped into internal and external bus types. Internal buses are considered to be inside the actual computer, while external or “expansion” buses are used to attach external devices to the computer. Good examples of internal buses are the aforementioned PCIe bus, the older Industry Standard Architecture (ISA) bus, and the very popular Small Computer Systems Interface (SCSI) bus. An example of an external or expansion bus type would be the most universally available Universal Serial Bus (USB) bus.
			}

			ls???{
				# First among these is the lspci command, designed to show the user the PCI buses and devices attached to them.
				# For viewing external devices, the lsusb command will show those that are specifically connected to the Universal Serial Bus (USB).
			}

			usb-devices{
				Another tool for viewing details about USB devices connected to the system is the usb-devices command. This is a script, which when executed will display information about the USB device that can otherwise be found in the /sys or /proc directories, including; the USB device number, vendor, port and more:

				in terminal{
					usb-devices | tail -n 15

					output{
						S:  Manufacturer=Avocent
						S:  Product=USB Composite Device-0
						S:  SerialNumber=20120430
						C:  #Ifs= 2 Cfg#= 1 Atr=c0 MxPwr=2mA
						I:  If#= 0 Alt= 0 #EPs= 1 Cls=03(HID  ) Sub=01 Prot=01 Driver=usbhid
						I:  If#= 1 Alt= 0 #EPs= 1 Cls=03(HID  ) Sub=01 Prot=02 Driver=usbhid

						T:  Bus=06 Lev=00 Prnt=00 Port=00 Cnt=00 Dev#=  1 Spd=12  MxCh= 2
						D:  Ver= 1.10 Cls=09(hub  ) Sub=00 Prot=00 MxPS=64 #Cfgs=  1
						P:  Vendor=1d6b ProdID=0001 Rev=04.04
						S:  Manufacturer=Linux 4.4.0-72-generic uhci_hcd
						S:  Product=UHCI Host Controller
						S:  SerialNumber=0000:00:1d.1
						C:  #Ifs= 1 Cfg#= 1 Atr=e0 MxPwr=0mA
						I:  If#= 0 Alt= 0 #EPs= 1 Cls=09(hub  ) Sub=00 Prot=00 Driver=hub
					}
				}
			}

			### If the user requires more information than the lspci and lsusb commands show normally, simply append a -v option to either command and a great deal more information will be shown; taking the output from one line per item to a stanza-based output where each item is shown with multiple details.

			### Finally, if a user has an issue with a component and is able to see that component mentioned in the lspci -v output, they can get more information about the malfunctioning component by referring to the multiple digit vendor and device code that prefaces the stanza for each device. For example, to get more information about the IDE interface from the machine above, the user can run the lspci command with the -v and -s options followed by the vendor and device code as a parameter. The -s option will allow for a domain to be specified which will display information solely about devices in that domain

			### To isolate the details of a specific USB device, find the vendor and device code in the output of the lsusb command, then use the lsusb command again, this time with the -v and -d options to get the isolated details of a device. The -d option will allow for a vendor or product ID to be specified, which will only display devices with that number.
		}

		Hardware Subsystems{
			tree{
				For example, in the /proc directory, you can use the tree command to show a hierarchical tree of the files and directories that are contained there. However, the listing will be many pages long, so using the less command will be of great benefit in scrolling up and down and looking at the output.

				in terminal{
					tree /proc | less

					output{
						/proc
						|-- 1
						|   |-- attr
						|   |   |-- current
						|   |   |-- exec
						|   |   |-- fscreate
						|   |   |-- keycreate
						|   |   |-- prev
						|   |   `-- sockcreate
						|   |-- autogroup
						|   |-- auxv
						|   |-- cgroup
						|   |-- clear_refs
						|   |-- cmdline
						|   |-- comm
						|   |-- coredump_filter
						|   |-- cpuset
						|   |-- cwd -> [Error\ reading\ symbolic\ link\ information]
						|   |-- environ
						|   |-- exe -> [Error\ reading\ symbolic\ link\ information]
						|   |-- fd [error opening dir]
						|   |-- fdinfo [error opening dir]
						|   |-- gid_map
						:
					}
				}
			}

			lshal{
				To view the list of devices and their attributes that have been stored by hald, execute the lshal command. The lshal command's output will likely contain thousands of lines of text. To see information about specific devices, make use of the grep command, as shown in the following example:

				in terminal{
					lshal | grep cdrom | grep true

					output{ // can be different
						storage.cdrom.dvd = true   (bool)
						storage.cdrom.mrw = true   (bool)
						storage.cdrom.mrw_w = true   (bool)
						storage.cdrom.support_media_changed = true   (bool)
						storage.cdrom.support_multisession = true   (bool)
					}
				}
			}

			D-Bus{
				# Finally, when programs want information about devices, they are able to query hald by using D-Bus.

				# D-Bus is a method of allowing inter-process communications, primarily the communications between components in the Linux Desktop environments, KDE and GNOME. Without D-Bus, desktop environments will communicate between components with many separate processes, each requiring its own one-to-one communication with other components. This produces a confusing communications environment and can contribute to inefficiency and a lack of reliability and instability in the graphics subsystem.

				# D-Bus is a software bus that allows individual and groups of processes to communicate on a single virtual bus or channel, a feature called Interprocess Communication (IPC).
			}
		}

		key terms{
			
			/dev/
				Hardware devices are made available through special files under the /dev directory.
				Section 15.6 
			/proc/
				The process information pseudo-filesystem
				Section 15.6 
			/sys/
				The mount point for sysfs providing a set of virtual files by exporting information about various kernel subsystems, hardware devices and associated device drivers from the kernel's device model to user space.
				Section 15.6 
			lsmod
				Prints the contents of the /proc/modules file
				Section 15.7 
			lspci
				Prints detailed information about all PCI buses and devices in the system
				Section 15.5 
			lsusb
				Prints detailed information about all USB buses and devices in the system
				Section 15.5 
			modprobe
				Used to add a loadable kernel module (LKM) to the Linux kernel or to remove an LKM from the kernel
				Section 15.7 
			swap space
				Used when the amount of physical memory (RAM) is full. If the system needs more memory resources and the RAM is full, inactive pages in memory are moved to the swap space.
				Section 15.2.2 
		}
	}
}

chapter 16{
	in class{
		Basic Input Output System (BIOS)
				-The first program 
				-runs from ROM
				-OS independent
		Power over self-test (POST)
				-Power-on self-test core hardware check 
		Boot an OS from a Storage device
				-Proceed through the list until it finds a MBR 
		(MBR) Master Boot Record
				-First sector of the drive normally 512MB of storage space
				- Bootloader may reside in the MBR
				-And/or may reside elsewhere
		MBR runs the bootloader
				-Bootloader loads the OS
				-May be automatic or prompt for options
				-LILO, GRUB, GRUB2
				May create an initrd image initial ramdisk
				-“Initial ramdisk”
				-A RAM based file system
		Bootloader loads the kernel
				-/boot/vmlinuz
				-the kernel may be a compressed file
		Gets the hardware running
				-Linux run command
				File system is mounted
				-kernel runs init or systemd
	}

	The boot process takes place in four main stages, some of which are modified by administrators, while for the others, it is sufficient just to be aware of the actions taking place{
		1. Firmware Stage
		2. Bootloader
		3. Kernel Stage
		4. Init Stage
	}

	BIOS{
		# Most PC firmware is referred to as the Basic Input/Output System (BIOS). The BIOS is stored on the motherboard in non-volatile memory such as Read Only Memory (ROM) or flash memory.

		The BIOS has three main jobs to perform as part of the first stage of the boot process{
			
			1. Execute a power-on self test (POST) in order to ensure the hardware of the system is functioning properly. The POST runs some basic functional checks on the CPU, memory, and peripherals so that obvious errors, such as missing memory chips or malfunctioning disk devices are found early in the boot cycle.

			2. Enumerate available hardware such as memory, disks, and USB devices.

			3. Find the proper boot drive from the available storage devices and load the Master Boot Record (MBR) from that device. The Master Boot Record is the first sector (or 512 bytes) of the disk.
		}
	}

	# The most common bootloader used on machines is the Grand Unified Bootloader (GRUB). The latest version of GRUB supports booting Linux from a system using UEFI, interactive editing of the menu during bootup, and much more.

	Consider This{
		Outside of the IBM PC compatible architectures, there are additional bootloaders that are used. For Linux systems to boot on Sparc hardware, there is Sparc Improved bootLOader (SILO), and for PowerPC hardware, there is Yet Another BOOTloader (YABOOT).
	}

	# ‌⁠​​⁠​ It is also possible to boot off the network through the Preboot Execution Environment (PXE). In the PXE system, a compatible motherboard and network card contain enough intelligence to acquire an address from the network and use the Trivial File Transfer Protocol (TFTP) to download a special bootloader from a server.

	init{
		The init stage finishes booting the system. The first process of the operating system (also called init) is started. The init process has three important responsibilities{
			1. Continue the booting process to get services running, login screens displaying, and consoles listening.
			2. Start all other system processes.
			3. Adopt any process that detaches from its parent.
		}
	}

	Kernel Messages{
		The dmesg command can be executed after booting the system to see the messages generated by the kernel during boot time. This is useful when the system doesn't appear to boot correctly; the messages displayed can help an administrator troubleshoot the boot process.
‌⁠​​⁠		 Kernel messages are stored in a ring buffer of limited size; therefore, the messages that are generated at boot time may be overwritten later as the buffer fills up. It is possible that some of the kernel messages generated at boot time may be stored in the /var/log/dmesg file. Each time the system boots, the /var/log/dmesg file is overwritten with the messages that were generated during the boot process.
		It is common to execute the dmesg command upon connecting a new device to the system. This allows the administrator to see how the kernel dealt with the new device and usually to see what path name the new device has been assigned.
	}
}

Chapter 17: Bootloaders{
	in class{
		What is the bootloader:
			- is a small programs that are used to load other programs

			Type of bootloaders:
			- GRUB Grand unified bootloader -->lagacy
			- GRUB2
			- LILO Linux loader old type of bootloader

			- Primary task of the bootloader is to load the kernel

		To install bootloader GRUB:
			sudo grub-mkconfig -o /boot/grub/grub.cfg

		GRUB2
			Dynamically loaded modules
			Non-Ascii charater support
			boot from any partition LVM

			/boot/grub/grub.cfg

			update-grub or grub2-mkconfig

		Install GRUB
			/sbin/grub2-install /dev/sda1
			sudo grub-mkconfig -o /boot/grub/grub.cfg
			update-grub //create boot file in debian distribution
	}

	GRUB Legacy Boot Steps{
		All bootloaders work in stages, as the location for the initial bootloader code is very small, under 512 KB, and GRUB Legacy gets around this by utilizing 2.5 stages to load the entire bootloader and reach the main system’s bootloader.
		GRUB Legacy typically writes the stage 1 bootloader to the Master Boot Record (MBR), and that is just enough code to get the stage 1.5 bootloader, which usually occupies the first 30KiB of the disk that directly follows the MBR. The stage 1.5 loader has just enough code to load up the filesystem drivers needed to load the stage 2 loader from the /boot/grub location.
		The GRUB Legacy bootloading stages will then turn over the rest of the system initialization to the /sbin/init or systemd equivalent for the continuation of the system boot.
	}

	GRUB Legacy Configuration{
		in terminal{
			grub-mkconfig -o /boot/grub/grub.cfg
			# In the example above, the -o option specifies the output location, which is the /boot/grub/grub.cfg file. That file will contain the gathered information formatted accordingly and should be what the system needs to boot the currently installed system properly.
		
			# While the location of grub.conf is the /boot/grub/grub.conf file, on some systems a symbolic link named /etc/grub.conf makes it easier for the administrator to find
			in terminal{
				ls -l /etc/grub.conf
				output{
					lrwxrwxrwx 1 root root 22 Jun 18  2012 /etc/grub.conf -> ../boot/grub/grub.conf
				}
			}

			Keep in mind that only the root user can modify the /boot/grub/grub.conf file. A typical /boot/grub/grub.conf file would look something like the following{
				#global options
				default=0
				fallback=1
				timeout=5
				splashimage=(hd0,0)/grub/splash.xpm.gz
				hiddenmenu
				password notencypted

				#bootable title sections
				title CentOS (2.6.32-358.6.1.el6.i686)
					root (hd0,2)
					kernel /vmlinuz-2.6.32-358.6.1.el6.i686 ro root=/dev/mapper/vg_livecd-lv_root rd_NO_LUKS LANG=en_US.UTF-8 rd_LVM_LV=vg_livecd/lv_swap rd_NO_MD rd_LVM_LV=vg_livecd/lv_root SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet
					initrd /initramfs-2.6.32-358.6.1.el6.i686.img
				title CentOS (2.6.32-358.2.1.el6.i686)
					password --md5 $1$D20Ia1$iN6djlheGF0NQoyerYgpp/
					root (hd0,2)
					kernel /vmlinuz-2.6.32-358.2.1.el6.i686 ro root=/dev/mapper/vg_livecd-lv_root rd_NO_LUKS LANG=en_US.UTF-8 rd_LVM_LV=vg_livecd/lv_swap rd_NO_MD rd_LVM_LV=vg_livecd/lv_root SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet
					initrd /initramfs-2.6.32-358.2.1.el6.i686.img
				title OtherOS (Windows)
					rootnoverify (hd0,0)
					chainloader +1
			}
		}

		info{
			Directive 			Meaning
			default= 			Specifies the title to attempt to boot by default after the timeout number of seconds has passed.
			fallback= 			Specifies the title to attempt to boot if the default title fails to boot successfully.
			timeout= 			Specifies the number of seconds to wait before automatically attempting to boot the default title.
			splashimage= 		Specify a background graphic that appears behind the text of the menu.
			hiddenmenu 			Prevents GRUB Legacy from displaying all but the default bootable title until the user presses a key. If the user presses a key, then all titles are displayed.
			title 				The title directive starts a new block of directives that form the directives necessary to boot the system. A title block ends when the next title directive appears or when the end of the file is reached.
			root 				Uses the special hard disk syntax to refer to the location of the /boot directory.
			kernel 				This line specifies the kernel image file, followed by all the parameters that are passed to the kernel, such as ro for read-only and root=/path/to/rootfs.
			initrd 				This line should specify an initial ramdisk that matches the version and release of the Linux kernel. This file provides a minimal filesystem during kernel initialization prior to mounting the root filesystem.
			password 			This option can be used as either a global option or a title option. When specified globally, this requires the user to submit the specified password before appending, editing, or using the GRUB Legacy command line. As a title option, this requires the user to submit the password before GRUB will attempt to boot the title.
			rootnoverify 		This directive is used to specify a bootable partition for a non-Linux operating system.
			chainloader 		Used to specify a path to another bootloader or +1 if the bootloader is located in the first sector of the partition specified by the rootnoverify directive.
		}
	}

	Interacting with GRUB Legacy{
		# When a system first starts up with GRUB Legacy installed as the bootloader, it may only display the default title and the timeout time counting down to zero as the hiddenmenu directive may be specified in the /boot/grub/grub.conf file. If the hiddenmenu directive is not specified, then GRUB Legacy will display all the titles and the timeout time counting down to zero. If no interaction occurs before the countdown reaches zero, then GRUB Legacy will attempt to boot the default title.
		# If any key except Enter is pressed, then the time stops counting down, and a title must be selected manually to attempt a boot. The Up ↑ and Down ↓ arrow keys can be used to select one of the available titles. After selecting a title, the user can press Enter to attempt to boot the selection.
		# If the global password directive has been used, then the P key must be pressed, followed by the password to unlock the ability to use GRUB Legacy 's append, edit, and the GRUB command prompt features
	
		Notice the following options available at the bottom of the previous graphic{
			1. If the A key is pressed, then GRUB Legacy will allow additional kernel parameters to be appended. This is commonly used to specify the runlevel number to take the system to, instead of the default runlevel.
			2. If the E key is pressed, then any of the directives that are included within the selected title can be edited; the root, kernel, or initrd values can be changed in order to be able to boot the system in a different manner. The changes that are made at the GRUB Legacy menu are not permanently edited into the /boot/grub/grub.conf file.
			3. If the C key is pressed at the GRUB Legacy menu, then the GRUB command prompt will be provided. At this command prompt, any GRUB Legacy directives can be added, including specifying custom root, kernel, and initrd directives. If entered correctly, followed by the boot directive, then the system will boot correctly.
		}
	}

	key terms{
		grub-install
			Utility to install GRUB on the hard drive.
			Section 17.6 
		grub-mkconfig
			Utility used to generate a configuration file for GRUB.
			Section 17.8 
		grub.cfg
			GRUB configuration file.
			Section 17.8 
		grub.conf
			GRUB configuration file on Red Hat Linux.
			Section 17.6 
		menu.lst
			configuration file for GRUB legacy.
			Section 17.4
	}
}

chapter 18: Runlevels{
	in class{
		0 shuts down the system
		1 Single user mode for maintenance
		2 debian ditros multiuser mode with GUI
		3 Redhat Multiuser mode with text
		4 Undefined
		5 Red hat runlevel 3 with GUI
		6 Reboot the system
	}
	
	The wall Command{
		# There are instances when the notification may not require the imminent shutdown of the system. This is what the wall command is used for. The wall command can be used to display a message or the contents of a file to all users on the system. For example, the following message is being piped to the wall command from the echo command
		
		in terminal{
			echo -e "The server will be offline on Saturday from\n6:00PM to 12:00PM for scheduled maintenance" | wall Broadcast message from sysadmin@localhost (console) (Wed May 29 22:13:59 2019):

			output{
				The server will be offline on Saturday from
				6:00PM to 12:00PM for scheduled maintenance
			}
		}
	}

	Managing System Services{
		# As the administrator of a system, it is possible to control which services will be provided by the various daemons (processes that run in the background of the system). If you want to test services out or have them temporarily enabled or disabled, then you could manually manage them.
		# Typically, administrators will want to automate the management of services, so when the system is taken to a specific runlevel or target state, they will know what services should automatically be available.
		# To manually manage the state of a service, such as a web server, use the appropriate script in the /etc/rc.d/init.d directory to start, stop, or otherwise change the state of the web server. To manage a service with these scripts, run the script with an argument which specifies what the script is supposed to do.
		# For example, on a Red Hat Enterprise Linux distribution, the script to manage the web server has a path name of /etc/rc.d/init.d/httpd. So, to manually start the web server, you would execute the following command as the root user:

		in terminal{
			[root@localhost ~]# /etc/rc.d/init.d/httpd start
			Starting httpd:

			---------------------------------------------------

			[root@localhost ~]# /etc/rc.d/init.d/httpd stop
			Stopping httpd:

			-----------------------------------------------------

			[root@localhost ~]# service httpd start
			[root@localhost ~]# service httpd stop

			-------------------------------------------------------

			[root@localhost ~]# service httpd restart

			-----------------------------------------------------

			[root@localhost ~]# /etc/init.d/httpd
			Usage: httpd {start|stop|restart|conderestart|try-restart|force-reload|reload|status|fullst
			atus|graceful|help|configtest}
		}

		Argument 		Function
		start 			If the service is not running, then attempt to start it.
		stop 			If the service is running, then attempt to stop it.
		restart 		Stop and then start the service over. If a major configuration change is made to a service, it may have to be restarted to make the change effective.
		condrestart 	Restart the service on the condition that it is currently running.
		try-restart 	Same as condrestart.
		reload 			Read and load the configuration for the service. Reloading the configuration file of a service is normally a less disruptive way to make configuration changes to a service effective, but may not be successful for major changes.
		status 			Show whether the service is stopped or the process id (PID) if the service is running. Note: It is also possible to use the service --status-all command to see the status of all daemons.
		fullstatus 		For the Apache web server, displays the URL /server-status.
		graceful 		For the Apache web server, it gracefully restarts the server. If the server is not running, then it is started. Unlike a normal restart, open connections are not aborted.
		help 			Displays the usage of the script.
		configtest 		Checks the configuration files for correctness. For some services, if the configuration file is modified, then this can be used to verify that the changes have no syntax errors.
	}

	Runlevel Directories{
		# The number in the directory name represents the runlevel that it manages; for example, rc0.d is for runlevel 0 and rc1.d is for runlevel 1. To demonstrate, the directories that are used to manage which services will be automatically started or stopped at different runlevels in our VM can be found in the /etc directory. To display these directories, execute the following command:
		
		in terminal{
			sysadmin@localhost:~$ cd /etc
			sysadmin@localhost:/etc$ ls -d rc*
			rc0.d  rc1.d  rc2.d  rc3.d  rc4.d  rc5.d  rc6.d  rcS.d
		}

		# So, what number is supposed to be provided to a specific script for S and K? Look at the script itself for the line that contains chkconfig:

		in terminal{
			[root@localhost ~]# grep chkconfig /etc/init.d/httpd
			# chkconfig: - 85 15
		}

		# The second to last number 85 of the chkconfig line is the S number to place on this script, the last number 15 is the K number.
	}

	The chkconfig Command{
		# To view all the services that are set to start or stop automatically, the administrator can execute the chkconfig --list command and the output would look something like the following (although there would be many more lines of output):

		in terminal{
			[root@localhost ~]# chkconfig --list
			auditd          0:off   1:off   2:on    3:on    4:on    5:on    6:off
			crond           0:off   1:off   2:on    3:on    4:on    5:on    6:off
			httpd           0:off   1:off   2:off   3:off   4:off   5:off   6:off
			iptables        0:off   1:off   2:on    3:on    4:on    5:on    6:off
			netconsole      0:off   1:off   2:off   3:off   4:off   5:off   6:off
			netfs           0:off   1:off   2:off   3:on    4:on    5:on    6:off
			network         0:off   1:off   2:on    3:on    4:on    5:on    6:off
			quota_nld       0:off   1:off   2:off   3:off   4:off   5:off   6:off
			rdisc           0:off   1:off   2:off   3:off   4:off   5:off   6:off
			restorecond     0:off   1:off   2:off   3:off   4:off   5:off   6:off
			rsyslog         0:off   1:off   2:on    3:on    4:on    5:on    6:off
			saslauthd       0:off   1:off   2:off   3:off   4:off   5:off   6:off
			sendmail        0:off   1:off   2:on    3:on    4:on    5:on    6:off
			sshd            0:off   1:off   2:on    3:on    4:on    5:on    6:off
			udev-post       0:off   1:on    2:on    3:on    4:on    5:on    6:off
		}

		# To view a single service's settings, use the chkconfig --list SCRIPT command where SCRIPT is the name of a script file found in the /etc/rc.d/init.d directory. For example, to view the web server script, execute:

		in terminal{
			[root@localhost ~]# chkconfig --list httpd
			httpd            0:off   1:off   2:off    3:off    4:off    5:off    6:off
		}

		# To enable the service to start for most runlevels, use the chkconfig SERVICE on command, where the SERVICE is the name of a script file found in the /etc/rc.d/init.d directory. Thus, to enable the web server to start at most runlevels, execute the chkconfig httpd on command:

		in terminal{
			[root@localhost ~]# chkconfig httpd on
			[root@localhost ~]# chkconfig --list httpd
			httpd            0:off   1:off   2:on    3:on    4:on    5:on    6:off
		}
	}

	The /etc/init Directory{
		# For Debian and its derivatives (like Ubuntu), know that the runlevels that are used vary slightly from those defined by the Linux Standard Base 4.1. Runlevels 0, 1, and 6 are the same as the standard. However, runlevel 2 is considered the default runlevel; this runlevel is configured for multiple users with the GUI running, much like the standard runlevel five. Runlevels 3, 4, and 5 are initially the same as runlevel 2.
		
		# If an administrator wants to change the runlevels of a service, the configuration file for that service can be modified in the /etc/init directory. For example, in an installation of Ubuntu which includes the Apache web server, this directory normally contains the /etc/init/apache2.conf Upstart configuration file. Within the /etc/init/apache2.conf file should be two lines which define the runlevels to start and stop the server:

		in terminal{

			start on runlevel [2345]
			stop on runlevel [!2345]
			
			--------------------------------

			# In this case, the service would be started up in runlevels 2 through 5 and would be stopped in runlevels that are not 2 through 5 because the ! character indicates "not these". To change the service to only be available in runlevels 2 and 3, change the lines to be like the following:

			start on runlevel [23]
			stop on runlevel [!23]
		}

		# To disable a service without uninstalling it, an override file can be created in the /etc/init directory. This file should have the same name as the service configuration file, but ending in .override instead of .conf. This is the preferred technique over commenting out the "start on" lines.

		# The contents of the .override file should simply be the word manual, which means that the service will ignore any "start on" lines from the configuration file. For example, to override the apache2 configuration file and disable the web server, execute the following command:

		in terminal{
			[sysadmin@localhost ~]$ sudo 'echo manual > /etc/init/apache2.override'
		}
	}

	The systemctl Command{
		# The systemctl command is used in systems that have systemd as a replacement for the traditional init process. This one command can be used to manually control the state of services, enable or disable automatic starting of services, as well as change system targets.
		# The systemctl command looks in the /usr/lib/systemd directory for information about which symbolic link enables a specific service. This directory is where a service’s files are originally placed when it is installed.
		# It is also possible to edit service files in order to modify the service; however, these changes should be made to service files found in the /etc/systemd directory instead.

		# To manually control the state of a service, use the systemctl command to start, stop, or check the status of that service. For example, to start a service like the web server, execute the following:

		in terminal{
			systemctl start httpd.service

			-----------------------------

			# To shut down the service:

			systemctl stop httpd.service

			-----------------------------

			# To check the state of the service:

			systemctl status httpd.service

			### To view the status of all services use -a or --all

			-------------------------------------------------------

			# To configure a service to start automatically, execute the following:

			systemctl enable httpd.service

			---------------------------------------------------------------------------

			# To configure a service not to start automatically, execute the following:

			systemctl disable httpd.service

			----------------------------------------------------------------------------

			# As previously mentioned, it is possible to change to a different runlevel with the systemctl command:

			systemctl isolate DESIRED.TARGET

			---------------------------------------------------------------------------------------------------------

			# The systemctl command can also manage the low or no power states of the system with command lines such as:

			systemctl hibernate
			systemctl suspend
			systemctl poweroff
			systemctl reboot
		}

		# Similar to the chkconfig --list command, all the services that are supposed to be enabled for a specific target within systemd can be viewed by using a systemctl list-dependencies command for that target, such as:
		# The partial output below shows each level of wanted services below a target and the dependencies between each target indented. You see services like atieventsd.service and gdm.service are wanted by the graphical.target.
		# Also, the graphical.target depends on the multi-user.target and the multi-user.target wants the services abrt-ccpp.service and abrt-oops.service.

		in terminal{
			[root@localhost ~]# systemctl list-dependencies graphical.target
			graphical.target
			├─atieventsd.service
			├─gdm.service
			├─jexec.service
			├─systemd-readahead-collect.service
			├─systemd-readahead-replay.service
			├─systemd-update-utmp-runlevel.service
			├─abrt-ccps.service
			├─abrt-oops.service
		}

		## Consider This{
			Because there are three different types of boot systems, traditional init, Upstart and systemd, the logical question is, "Which one does my system use?" The easy answer to this question is to check for the existence of two directories: the /etc/init and the /etc/systemd directory.
			If your system has a /etc/init directory, then your system is using Upstart. If your system has a /etc/systemd directory, then your system is using systemd. Otherwise, your system is using traditional init.
		}
	}

	Boot Target{
		# Many modern systems use systemd rather than init for setting boot targets. The following table shows the runlevel equivalents for boot targets.

		Runlevel 		Purpose 																		systemd Target
		0 				Halt or shut off the system 													poweroff.target
		1 				Single-user mode for administrative tasks 										rescue.target
		2 				Multi-user mode without configured network interfaces or network services 		multi-user.target
		3 				Normal startup of the system 													multi-user.target
		4 				User-definable 																	multi-user.target
		5 				Start the system normally with a graphical display manager 						graphical.target
		6 				Restart the system 																reboot.target
	}

	acpid{
		# Linux systems use the Advanced Configuration and Power Interface (ACPI) event daemon acpid to notify user-space programs of ACPI events. The ACPI allows the kernel to configure hardware components and manage the system’s power settings, such as battery status monitoring, temperature, and more.
		# One example of using acpid for power management would be having the system shut down after the user presses the power button. On modern systems, acpid is normally started as a background process during bootup and opens an event file in the /proc/acpi directory. For example, the wakeup file in the /proc/acpi directory below displays the following information:

		in terminal{
			sysadmin@localhost:~$ su -
			Password:
			root@localhost:~# ls -l /proc/acpi
			total 0
			-rw-r--r-- 1 root root 0 May 28 21:09 wakeup
			root@localhost:~# cat /proc/acpi/wakeup
			Device  S-state   Status   Sysfs node
			PCI0      S5    *disabled  no-bus:pci0000:00
			root@localhost:~#
		}

		## When the kernel sends out an ACPI event, acpid will determine the next steps based on rules defined in configuration files in the /etc/acpi directory. Administrators can create rules scripts in the /etc/acpi directory to control the actions taken by the system.

		# The acpi command is used to display information about system hardware ACPI settings, it’s not installed on our VM, but the above example shows a basic acpi script in the /proc/acpi directory that controls waking the machine up after being suspended. There are many options available to the acpi command to display various information for power management. The table below summarizes some of the options available to the acpi command:

		Option 				Purpose

		-b | --battery		Displays battery information

		-a | --ac-adapter	Displays ac adapter information

		-t | --thermal 		Displays thermal information

		-c | --cooling 		Displays cooling device information

		-s | --show-empty 	Displays non-operational devices

		-f | --fahrenheit	Uses Fahrenheit as the temperature unit instead of the default, Celsius

		-i | --details		Displays additional details if they are available; battery capacity and temperature trip points
	}

	key terms{
		
		/etc/init.d/
			Contains scripts used by the System V init tools (SysVinit)
			Section 18.6 
		/etc/inittab
			Configuration file read by init when it starts up to determine what process to start for various run levels.
			| Section 18.2 
		/etc/systemd/
			The location of various unit files that control services controlled by systemd.
			Section 18.11 
		/usr/lib/systemd/
			The location of services provided by installed packages.
			Section 18.11 
		init
			The parent of all processes on the system, it is executed by the kernel and is responsible for starting all other processes.
			| Section 18.4 
		shutdown
			Arranges for the system to be brought down in a safe way. All logged-in users are notified that the system is going down and, within the last five minutes of TIME, new logins are prevented.
			Section 18.4 
		systemctl
			The interface to systemd, the init system used by many Linux distributions. It combines the functionality of both service and chkconfig into a single tool that you can use for instance to enable/disable services permanently or only for the current session.
			Section 18.11 
		systemd
			A full replacement for init with parallel starting of services and other features, used by many distributions.
			| Section 18.1 
		telinit
			Signal init to change the system's runlevel. telinit is actually just a link to init, the ancestor of all processes.
			Section 18.4 
		wall
			Displays a message, or the contents of a file, or otherwise its standard input, on the terminals of all currently logged in users.
			Section 18.5 
	}
}


chapter 19 and 20{
	in class{
		Display disks and partitions:
			df -h
			ls /dev/sd*
			ls -i //lists all files and directories with Inode number.



		Creating partitions from command line:
			fdisk:
			sudo fdisk -l /dev/sda //lists existing partitions on a device
			sudo fdisk <partition_name> //an interactive tool that doesn't make change until you "save"



		sudo fdisk /dev/sda
			-p print partition information
			-n create new partition
			-e extended
			-p primary
			-t //change partition type
			-L //display a list of partitions types
			-d //delete a partition
			-q //quit without saving
			-w //to save changes and quit



		sfdisk Scriptable fdisk-like program for automate partitioning
			also used to backup and restore current partition table.
			sfdisk
			sudo sfdisk -s //list disk and sizes
			sudo sfdisk -d /dev/sda1 > sdb1.backup //backup current table before making changes



		creating filesystems
			mkfs -t vfat /dev/sda1 //create a file system



		creating a swap space:
			mkswap /dev/sda1 //initialize a swap partition
			mkswap -L myswap /dev/sda1
			swapon /dev/sda2 //enable swap space
	}

	me read chapter 19{
		Understanding Partitioning{
			# Partitioning is necessary in order to optimally use the space that hard drives (hard disks) provide. A new hard drive is like a completely empty building, with no internal walls or floors. As it is, such a building wouldn't be useful, but populating the building with walls and floors would provide the structure needed to make use of the building.

			There are three steps in the process of making and using partitions:{
				1. Divide the hard drive into partitions.
				2. Create and format filesystems inside the partitions.
				3. Mount the filesystem into the directory tree.
			}
		}

		Partition Limitations{
			# Historically, the number of partitions a system can have is limited by the Master Boot Record (MBR). Recall that the MBR is usually contained within the first sector or 512 bytes of the disk and contains a bootloader program, as well as the partition table. The partition table contains the definition of each partition on the hard drive, including the starting cylinder, ending cylinder, and size.

			# Up until now, we’ve only discussed MBR partitioning; however, some hard drives make use of another partitioning type called the GUID Partition Table (GPT). A globally unique identifier (GUID) is a universally unique 128-bit number used to identify information on a computer system. This partitioning scheme was designed to replace the traditional MBR partitioning in use since PC DOS 2.0 was introduced in 1983 and is available on systems that support the Unified Extensible Firmware Interface (UEFI).

			# GPT supports very large disks, up to 9ZB in size. Extended and logical partitions are not used with GPT; instead, all partitions are the same, and GPT supports a maximum of 128 partitions per disk. Creating GPT partitions is accomplished using a partitioning tool called gdisk, which is similar to the fdisk utility that is used for MBR partitions.

			# In addition to MBR and GPT partition tables, there are other methods for dividing up the disk, including Berkeley Software Distribution (BSD) Unix Labels, Apple Partition Maps, and others. Also, there are tools to use partitions in more flexible and dynamic ways, like Logical Volume Management (LVM).
		}

		Filesystem{
			# Next, we'll examine the concept and purpose of the filesystem in regards to partitioning. In order to place files and directories on a partition, a filesystem needs to be created. This is accomplished by formatting the partition. A filesystem provides the operating system with a way to organize the files and directories. Moreover, a filesystem stores information about files, such as the permissions of the files, the owner of the files, and the file type.
			# An analogy that may help in understanding filesystems is to consider the library example previously mentioned. A library has thousands of books (think files) that need to be organized in a manner that makes it easy to find a specific book. In order to do this, the books are organized into categories (think directories). However, just putting books into directories isn't sufficient since a single category can contain hundreds or even thousands of books.
			# To better organize all of the books in the library, a system such as the Dewey Decimal System is used. This system provided a central catalog of index cards, normally located in a cabinet at the front of a section where individuals could determine the exact location of a specific book. Included in the catalog is metadata about each book, such as publication date, author, publisher, etc. A key component of this metadata is a unique identification number for each book

			# Metadata about the file will be contained in this entry, which includes file attributes like ownership, timestamps, data block locations, and everything about the file except for its contents. The entry also includes a unique identification number for the file, called an inode number and pointers (or links) that inform the operating system of the location in the filesystem (where on the hard drive) the file's data is stored.
			## Keep in mind that there is more than one way to organize books in a library. For example, in addition to the Dewey Decimal System, there is a system called the Library of Congress Classification system that performs the same function as the Dewey Decimal System but uses a different technique. The same holds true for the filesystems available for Linux; there is more than one type available, and each uses a different technique. Some of the more common filesystem types include:

				Type() 					Name() 								Advantages()																																						Disadvantages()
				ext2 					Second Extended Filesystem 			Works well with small and solid-state disk filesystems 																												No journaling capability, making it susceptible to data loss in the event of power loss.
				ext3 					Third Extended Filesystem 			Can be upgraded from existing ext2 filesystem without data loss. This filesystem performs journaling, which allows for data recovery after a crash. 				Writes more to disk than ext2 because of journaling, making it slower. Does not support very large filesystems.
				ext4 					Fourth Extended Filesystem 			Support for very large disk volumes and file sizes. Can operate with or without a journal. Backwards compatible with ext3 and ext2. 								Not a huge improvement over ext3. No dynamic inode creation.
				xfs 					Extents Filesystem 					Works very efficiently with large files. Compatible with the IRIX operating system from SGI. Announced to be the default filesystem for RHEL 7. 					The filesystem cannot be shrunk.
				vfat 					File Allocation Table 				Supported by almost all operating systems. Commonly used for removable media. 																						Unable to support very large disks or files. Microsoft's intellectual property claims.
				iso 					ISO 9660 							The International Organization for Standardization standard for optical disc media that is supported by almost all operating systems. 								Multiple levels and extensions complicate compatibility. Not designed for rewritable media.
				udf 					Universal Disc Format 				Designed to replace ISO 9660 and adopted as the standard format for DVDs by the DVD Consortium. 																	Write support is limited to support revision 2.01 of the standard.
		}

		Linux Filesystem Components{
			# When talking about Linux the term filesystem often refers to the ext2/ext3/ext4 family of filesystems. While there are differences between these filesystems, they are similar enough when it comes to core filesystem components.
			## A full discussion of filesystem components is beyond the scope of this course, and also presents somewhat of a moving target with virtualization and cloud computing gaining prominence. However, since Linux still operates by the kernel communicating with external resources, all system administrators need to be familiar with the key filesystem components described below:

				Component 		Description
				Superblock 		At the beginning of the filesystem is an area called the superblock. This area is used to store important information about the filesystem, including the size of the filesystem, the type of filesystem, and which data blocks (where file data is stored) are available. The superblock is a key component of the filesystem; a corrupted superblock would make the filesystem inaccessible.
				Group Block 	The filesystem is divided into smaller sections called groups. The group block serves to hold data about the group. Each group block also contains a backup copy of the superblock.
				Inode Table 	Each file is assigned a unique inode number for the filesystem. This inode number is associated with a table that stores the file's metadata.
		}

		Physical vs. Virtual Filesystems{
			# On Microsoft Windows, this is accomplished by assigning drive letters to each partition. The first partition is typically referred to as the C: drive (which is poorly named as it is actually a partition, not an entire drive). Newer Microsoft Windows systems may come with multiple partitions, resulting in partitions such as D:, E:, and F:. Note that A: and B: were previously used for floppy drives and are not typically used for hard drive partitions.

			## In Linux, there are no drive letters. Instead, each partition is assigned a device file name as mentioned previously:

				Device Types 				Partition Name 		Example
				SATA, SCSI, USB 			/dev/sda* 			/dev/sda1
																/dev/sda2

				PATA/IDE 					/dev/hda* 			/dev/hda1
																/dev/hda2
		}

		Why Create Partitions?{

			Supporting Multiple Operating Systems{
				Some systems may contain Linux as well as a Microsoft Windows operating systems; these are called dual boot systems. Because the filesystems that are used with Microsoft Windows are different than Linux, this requires multiple partitions.
			}

			Home Directories{
				## A separate partition for the user home directories is common and typically provides many advantages, including:

					1. It is easier to backup or restore an entire filesystem than it is to manage each user's home directory. Recall that each partition has a separate filesystem.

					2. When home directories are separated from the root filesystem, upgrades of the operating system can be performed much more safely and efficiently.

					3. Filesystems can have features enabled on them, such as disk quotas. A disk quota allows the administrator to limit how much space a user uses in a filesystem. Being able to create a disk quota for the home directories that doesn't affect the rest of the operating system can be an advantage.
			}

			Common Writable Directories{
				# Some directories, such as the /tmp and /var/tmp directories, are world writable. This means that any user can store files in these directories without any limitations, by default. Unfortunately, that can cause problems if these directories are not placed on separate filesystems.
				## If the /tmp and /var/tmp directories are not mount points, then files placed in these directories will go on the same partition as the / filesystem. If a user creates a very large file, then he could end up filling up the entire / filesystem. This would make the operating system unusable by all other users (except the root user for whom some space is reserved).
				## Separating the /tmp and /var/tmp directories allows the administrator to enable disk quotas to limit how much space can be used by each user in those directories. Even if no quotas are put into effect, having directories on a separate partition means if a regular user fills up the partition(s) /tmp or /var/tmp are located on, the root filesystem or other critical filesystems are not affected.
			}

			Security{
				## Using separate partitions may enhance security. Since each partition has separate inodes and data blocks, corruption to a single partition will be contained to its mount point within the virtual filesystem. Therefore, spreading files across multiple partitions is safer than having one partition that contains everything under the root directory.
				# Sometimes a collection of files, perhaps old databases, need to be stored but shouldn't be modified. By placing them on a separate filesystem, that partition can be mounted as read-only to prevent any alteration.
			}

			Heavily Active{
				# If running out of space is a concern due to heavy activity within a directory, it may be desirable to have it mounted on a separate partition. This is often the case for directories like the /var/log directory where the system adds log file data on a regular basis.
				## When system processes (as opposed to regular users) write to the disk, quotas are not usually used to limit the space. Instead, these types of directories are mounted on separate filesystems so that if they fill up then it won't fill up the root / filesystem. While this may be bad because log files aren't generated, it is better than filling up the root / filesystem and making the operating system unusable for regular users.

				##Another type of partition that is useful in making system tasking more efficient is swap space. To describe the concept of swap space, we will use another analogy of a physical library. In a library, there are always new books coming in and old ones going out. These books are usually kept in a storage room or basement, still organized but separate from the main shelves. If a book is being transferred, it is pulled from this storage and sent to another library where it will be used. In a computer filesystem, this area is called swap space. This is a location on the physical drive where data is stored while programs are using it. It emulates random access memory (RAM) and frees up the actual physical memory for other processing tasks. This allows the operating system to quickly provide information in files without having to read and write it to the main storage areas. When the user is finished with this data, it is written to the appropriate area on the drive, and the swap space is freed up for the next task. Swap space on an operating system can take the form of a dedicated partition (swap partition), a file (swap file), or both.
			}
		}

		Partitioning Layout{
			# There are some requirements in the way partitions will map to the directories that they mount on. These requirements are documented in what is called the Filesystem Hierarchy Standard (FHS). The following table summarizes the FHS requirements, and provides some other suggestions:

				Directory 			Purpose																																																						Suggested Size
				------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
				/ 					The root filesystem holds the files essential to the operation of the system. It must contain the following directories or symbolic links: bin, boot, dev, etc, lib, media, mnt, opt, sbin, srv, tmp, usr, and var. 		500MiB-50GiB+
																																																																Depends on what is mounted separately
				------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
				/boot 				The /boot directory contains the Linux kernel and the boot loader files. 																																					500MiB-2GB
				------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
				/home 				The /home directory is where user home directories are normally created. 																																					500MiB+ per user
				------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
				/tmp 				The /tmp directory is used to create temporary files for the system and users. If this directory is too small, it may prevent applications from functioning correctly. 														Minimum of 5 GB +
																																																																500MiB+ per user actively logged in
				------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
				/opt 				The /opt directory is where third-party software is often installed. Some examples include Google Chrome and Google Earth. 																									100MiB+
																																																																Depends on how many packages are installed
				------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
				swap 				Swap is virtual memory that is not mounted on a directory. This virtual memory is used when the actual memory of the system is low. On systems with large amounts of memory, swap is less important. 						Up to 2 times the physical memory of the system
				------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
				/usr 				The /usr directory contains the bulk of the operating system's files, including most of the commands and system software. 																									2GiB-10GiB+
				------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
				/usr/local 			This directory is used for locally installed software that should not be upgraded or updated with the operating system. 																									100MiB+
																																																																Size depends on local needs
				------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
				/var 				There are many directories that may have heavy activity under /var for services like mail, ftp, http, and printing. 																										100MiB
																																																																Depending on the volume of activity
				------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
				/boot/efi 			The /boot/efi directory contains the Linux kernel and the boot loader files. It is typically set up automatically by the installer. 																						100MB-250MB
		}
	}

	me read chapter 20{
		20.2 Creating Partitions During Installation{
			When choosing one of these options, the following should be taken into consideration:{		

				1. Use All Space: Use this option when there is no need to save any data from the existing hard drive. This option will remove all traces of any previous hard drive data, including previous installations of other operating systems.

				2. Replace Existing Linux Systems: Use this option when the system is a dual boot system, typically a system with both a Linux operating system and a Microsoft Windows operating system. Realize that all Linux operating systems will be replaced by this new installation. However, the Microsoft Windows operating system should not be impacted.

				3. Shrink Current System: This option would be used to recover hard drive space from an existing Linux operating system. The recovered space could then be used to install a second Linux operating system for a dual boot system. This is an advanced installation method, and all data from the existing Linux operating system should be backed up prior to using this method.

				4. Use Free Space: This option assumes that a previous operating system (Microsoft Windows or Linux) has already been installed and there is still unpartitioned space available on the hard drive. This is usually the case when creating a dual boot system as Microsoft Windows should be installed first without using all of the hard drive space. The remaining space is used by the Linux Installer to install the Linux operating system.
				
				5. Create Custom Layout: This option is used for advanced installations. The administrator is provided with the opportunity to remove existing partitions and create new partitions to meet the needs of the customized installation.
			}

			Components of this graphic:{
				
				Mount Point: The directory where the filesystem for this partition will be mounted.

				File System Type: The type of filesystem to place on this partition. The exact types that will be available during the installation will depend on what specific Linux operating system is being installed.

				Allowable Drives: This area provides a list of available hard drives. If only one hard drive is present, then it is greyed out. If multiple hard drives are present, then the individual who is performing the installation can choose which hard drive to place this partition on.

				Size (MB): The size in megabytes of the partition. Note that this relates to the next field.

				Additional Size Options:{

					Fixed Size: The partition will be the size specified by the Size (MB) field.

					Fill all space up to (MB): The partition will be at least the size specified by the Size MB field but can be as large as this field. For example, if the Size (MB) field is 500, and the Fill all space up to (MB) field is 800, then partition size will be between 500MB and 800MB. This is useful when the individual that is performing the installation creates partitions, and there is extra space left over. The installer will automatically take this extra space and assign it to partitions that make use of this field.

					Fill to maximum allowable size: The partition will be at least the size specified by the Size (MB) field. Any additional unpartitioned space will be given to this partition. If multiple partitions have this option, the unpartitioned space is divided equally between these partitions.

				}

			}
		}

		20.3 Creating Partitions After Installation{
			# One of the benefits of the fdisk tool is that it is very forgiving; if a mistake is made while using the tool, simply quit the program, and nothing will be changed on the system. Only when changes are written (saved) before quitting will the program update the partition table.
			# The fdisk program can be used in two ways: interactive and non-interactive. The interactive mode is used to modify the partitions, and the non-interactive mode is used to list partitions. In either mode, the fdisk program requires root privileges to run.

			### A couple of options can affect the output of the program when working with it in either mode. The units option -u will list the starting and ending locations for each partition in sectors instead of cylinders. Since Linux technically partitions by sector, it may be beneficial to use this option. If cylinders are used, the fdisk utility will translate into sectors, so using the -u option is only really required for fine tuning of partition sizes and to avoid seeing the following error message, arrowed below:

			in terminal {
				root@localhost:~# fdisk -l /dev/sda
				Disk /dev/sda: 11.3 GB, 11261706240 bytes
				255 heads, 63 sectors/track, 1369 cylinders
				Units = cylinders of 16065 * 512 = 8225280 bytes
				Sector size (logical/physical): 512 bytes / 512 bytes
				I/O size (minimum/optimal): 512 bytes / 512 bytes
				Disk identifier: 0x000ee7d2

				Device Boot      Start         End      Blocks   Id  System
				/dev/sda1   *           1          64      512000   83  Linux
				---->  Partition 1 does not end on cylinder boundary.  <--------
				/dev/sda2              64        1306     9972736   Linux LVM
				/dev/sda3           1306        1319     102400   82  Linux swap / Solaris
				---->  Partition 3 does not end on cylinder boundary.  <--------
			}

			consider this{
				# On almost every Linux distribution, the default fdisk output is displayed in cylinders. One exception is Ubuntu, which displays output in sectors by default. To display the output in cylinders, use the -u=cylinders option.
			}

			When using the fdisk utility, a warning will occur by default:{
				Warning
				DOS-compatible mode is deprecated.  It's strongly recommended to switch off the mode and change the display units to sectors.
			}

			# The -c option disables the warning regarding compatibility issues with the MS-DOS operating system. Although it is very unlikely that compatibility with this operating system will be an issue since DOS has not been available as a product for nearly twenty years, a warning will be issued if the -c option is not used.
		}

		20.3.1 Displaying Partitions{
			# To use fdisk in its non-interactive mode, add the -l option. To demonstrate, the following command will display a list of all partitions of all hard disk devices:

			in terminal{
				root@localhost:~# fdisk -cul
				Disk /dev/sda: 21.5 GB, 21474836480 bytes
				255 heads, 63 sectors/track, 2610 cylinders
				Units = cylinders of 16065 * 512 = 8225280 bytes
				Sector size (logical/physical): 512 bytes / 512 bytes
				I/O size (minimum/optimal): 512 bytes / 512 bytes
				Disk identifier: 0x000571a2

				Device Boot      Start         End      Blocks   Id  System
				/dev/sda1   *           1        2481    19921920   83  Linux
				/dev/sda2            2481        2611     1046529    5  Extended
				/dev/sda5            2481        2611     1046528   82  Linux swap / Solaris
			}

			Device Info{
				in terminal{
					Disk /dev/sda: 10.7 GB, 10737418240 bytes
				}
				# The device name and size of the device in bytes.
			}

			Columns{
				   	Device Boot   	    Start         End      Blocks  	 Id 	 System
					/dev/sda1   *           1        2481    19921920  	 83 	 Linux
					/dev/sda2            2481        2611     1046529  	  5 	 Extended
					/dev/sda5            2481        2611     1046528  	 82  	 Linux swap / Solaris
					---------------------------------------------------------------------------------

					Device 	->	The specific partition that the row is describing. For example, /dev/sda1 is the first partition on the first SATA hard drive.
					Start 	->	The starting sector of the partition.
					End 	->	The ending sector of the partition.
					Blocks 	->	The size of the partition in blocks.
					Id 		->	An identifier which is used to tell the kernel what type of filesystem should be placed on this partition. For example, the value 83 indicates that this partition should have an ext2, ext3, or etx4 filesystem type.
					System 	->	A human-readable name that indicates the type of filesystem the Id column refers to. For example, 83 is a Linux filesystem.
			}

			To see the partitions of a specific hard disk, add the pathname for the disk as an argument to the previous command.{
				in terminal{
					root@localhost:~# fdisk -c=dos -u=sectors -l /dev/sdb
					Disk /dev/sdb: 505 MB, 505413632 bytes
					5 heads, 52 sectors/track, 3796 cylinders, total 987136 sectors
					Units = sectors of 1 * 512 = 512 bytes
					Sector size (logical/physical): 512 bytes / 512 bytes
					I/O size (minimum/optimal): 512 bytes / 512 bytes
					Disk identifier: 0x7f08b2c3

					Device Boot  		Start     End 	 	Blocks   	Id  	System
					/dev/sdb1        	2552  	987135  	492292		6  		FAT16
				}
			}

			# The partition table described above is stored permanently in the MBR. When the system is booted, a copy is created in memory. This copy is used by the kernel for various system tasks. The kernel can't look directly at a filesystem to determine what type it is. So, the partition table stores this information for the benefit of the kernel. When the partition is created, it is the responsibility of the system administrator to indicate what type of filesystem will be placed on that partition by providing the partition type.


			Consider This{
				A useful tip for using fdisk in interactive mode is that a copy of the output of the fdisk -l command can be sent to a file on disk. Anyone who has ever made a mistake when partitioning a disk and needs to refer to the previous setup will appreciate having a copy of the exact cylinders and filesystems to refer to.

				in terminal{
					root@localhost:~# fdisk -l /dev/sda > mydisklayout.txt
				}
			}
		}

		20.3.2 fdisk Interactive Mode{
			# In the interactive mode, a system administrator can use the fdisk command to create and modify partitions. To enter the interactive mode, do not use the -l option, but still use -c and -u options. The pathname for the disk to edit is required. For example, to edit the partitions for the first SATA /dev/sda hard drive, execute the following command to display a prompt: {
				in terminal{
					root@localhost:~# fdisk -cu /dev/sda
					Command (m for help):

					# The m command will display a menu or help screen:

					Command (m for help): m

					Command action
					a   toggle a bootable flag
					b   edit bsd disklabel
					c   toggle the dos compatibility flag
					d   delete a partition
					l   list known partition types
					m   print this menu
					n   add a new partition
					o   create a new empty DOS partition table
					p   print the partition table
					q   quit without saving changes
					s   create a new empty Sun disklabel
					t   change a partition's system id
					u   change display/entry units
					v   verify the partition table
					w   write table to disk and exit
					x   extra functionality (experts only)
				}
			}

			# Before creating any partitions, it is a good idea to print the partition table by choosing the p command action. Note that this doesn't really send output to a printer, but to the screen instead. The output will look very much like the output of the fdisk -l command.{

				in terminal{
					Command (m for help): p

				Disk /dev/sda: 11.3 GB, 11261706240 bytes
				255 heads, 63 sectors/track, 1369 cylinders, total 21995520 sectors
				Units = sectors of 1 * 512 = 512 bytes
				Sector size (logical/physical): 512 bytes / 512 bytes
				I/O size (minimum/optimal): 512 bytes / 512 bytes
				Disk identifier: 0x000ee7d2

				Device Boot      Start         End      Blocks   Id  System
				/dev/sda1   *        2048     1026047      512000   83  Linux
				/dev/sda2         1026048    20971519     9972736   8e  Linux LVM
				}
			}
		}

		20.3.3 Creating Partitions{
			In order to create a new partition, the n command action should be chosen:{
				in terminal{
					Command (m for help): n
				}
				This command will prompt the system administrator to answer several questions, as described below.{
					Type of Partition ( in terminal ){
						Command Action
						e   extended
						p   primary partition (1-4)
					}

					The choices that are available to answer this question will vary, depending on what partitions already exist:‌⁠​​⁠​{
						
						1. If no extended partition has been created, the choices will be e for an extended partition or p for a primary partition.
						2 .If the extended partition has been created, the fdisk utility will automatically create a logical partition within the free space of the extended partition.
					}

					Partition Number ( in terminal ){
						Partition number (1-4): 3

						# When creating a primary partition, the fdisk utility will prompt for a partition number. Again, it is helpful to display the partition table to identify what the last partition number was and a numeric value of one higher. For example, if the last partition number was 2, then the next partition should be numbered 3.
						# When creating logical partitions, the fdisk utility will not prompt for a partition number and will assign a number by default.
					}

					Starting Sector ( in terminal ){
						First sector (20971520-21995519, default 20971520):

						# The next question asks where to start the new partition. Allocating this first sector should be extremely easy because the fdisk utility knows which sector is the next available. Pressing the Enter key accepts this value.

						Using default value 20971520

						!!! ## It is possible to type the sector number, but this is generally not recommended, as it may create unusable ranges of sectors.
					}

					Partition Size ( in terminal ){
						Last sector, +sectors, or +size{K,M,G} (20971520-21995519, default 21995519):

						# The last question asks what size the partition should be. There are three different techniques for assigning the last sector: last sector, +sectors, or +size: (still in terminal)
							# Using the last sector technique can be the hardest because there are a couple of calculations required. Sectors of a disk are generally 512 bytes in size, so to make a new 100 MB partition requires approximately 200,000 sectors. To calculate the last sector, add 200,000 to the value of the starting sector. Typically, the last sector technique is only used to utilize the rest of the available space. In that case, accept the default value by pressing the Enter key:
								Last sector, +sectors, or +size{K,M,G} (20971520-21995519, default 21995519):
								Using default value 21995519

							# Using the +sectors technique takes one less calculation than the last sector technique. With this technique, calculate the number of sectors needed and prefix it with the + plus sign. For example, to create a partition that is approximately 100MB, enter the value as +200000:
								Last sector, +sectors, or +size{K,M,G} (20971520-21995519, default 21995519): +200000
							
							# The final technique +size is normally preferred since no calculations are needed. Use the + plus sign, the size to make the partition, and a suffix to indicate the unit. For example, to specify the 100 MB size partition, enter the value for the ending sector as +100M:
								Last sector, +sectors, or +size{K,M,G} (20971520-21995519, default 21995519): +100M
					}
				}
			}

			The following is an example of an interaction with fdisk to create a new 100 MB partition using these steps:{
				
				1. The current partition table is displayed with the p command.
				2. The n command indicates a new partition is being created.
				3. The user enters p to create a primary partition.
				4. The partition is assigned as number 3.
				5. The default value for the first sector is chosen by pressing the Enter key.
				6. For the size, the user chooses +100M for a one-hundred-megabyte partition

				in terminal{
					Command (m for help): p

					Disk /dev/sda: 11.3 GB, 11261706240 bytes
					255 heads, 63 sectors/track, 1369 cylinders, total 21995520 sectors
					Units = sectors of 1 * 512 = 512 bytes
					Sector size (logical/physical): 512 bytes / 512 bytes
					I/O size (minimum/optimal): 512 bytes / 512 bytes
					Disk identifier: 0x000ee7d2

					Device Boot      Start         End      Blocks   Id  System
					/dev/sda1   *        2048     1026047      512000   83  Linux
					/dev/sda2         1026048    20971519     9972736   8e  Linux LVM

					Command (m for help): n
					Command Action
					e   extended
					p   primary partition (1-4)
					p
					Partition number (1-4): 3
					First sector (20971520-21995519, default 20971520):
					Using default value 20971520
					Last sector, +sectors, or +size{K,M,G} (20971520-21995519, default 21995519): +100M


					# After creating a partition, verify that it was correctly created by displaying the partition table:

					Command (m for help): p

					Disk /dev/sda: 11.3 GB, 11261706240 bytes
					255 heads, 63 sectors/track, 1369 cylinders, total 21995520 sectors
					Units = sectors of 1 * 512 = 512 bytes
					Sector size (logical/physical): 512 bytes / 512 bytes
					I/O size (minimum/optimal): 512 bytes / 512 bytes
					Disk identifier: 0x000ee7d2

					Device Boot      Start         End      Blocks   Id  System
					/dev/sda1   *        2048     1026047      512000   83  Linux
					/dev/sda2         1026048    20971519     9972736   8e  Linux LVM
					/dev/sda3        20971520    21176319      102400   83  Linux

					# When verifying this data, pay close attention to the Start and End sectors. Notice in the previous output that the starting sector of the /dev/sda3 partition is one value higher than the ending sector of the /dev/sda2 partition. Any overlap would result in data loss and should be avoided.

					!!! ## No changes have been made to the MBR, so it is possible to quit now in the event that any errors are displayed in the new partition table. To quit without saving changes, use the q command.
				}
			}
			!!!! The fdisk command is a destructive partitioning tool. Any changes to your partition structure may overwrite existing partition information and make data inaccessible.
			
			# In the next example, a fourth partition is added as an extended partition, and then two logical partitions are created within the extended partition. Notice that once the extended partition has been created, the fdisk utility skips the first two steps, since the partition is automatically designated as logical and assigned a number.{

				Command (m for help): n
				Command Action
				e   extended
				p   primary partition (1-4)
				e
				Partition number (1-4): 4
				First sector (21176320-21995519, default 21176320):
				Using default value 21176320
				Last sector, +sectors, or +size{K,M,G} (21176320-21995519, default 21995519):
				Using default value 21995519
				Command (m for help): n
				First sector (21178368-21995519, default 21178368):
				Using default value 21178368
				Last sector, +sectors, or +size{K,M,G} (21178368-21995519, default 21995519): +100M
				Command (m for help): n
				First sector (21385216-21995519, default 21385216):
				Using default value 21385216
				Last sector, +sectors, or +size{K,M,G} (21385216-21995519, default 21995519):
				Using default value 21995519

				# Notice that the logical partitions use starting and ending sectors that are within the extended partition:

				Command (m for help): p

				Disk /dev/sda: 11.3 GB, 11261706240 bytes
				255 heads, 63 sectors/track, 1369 cylinders, total 21995520 sectors
				Units = sectors of 1 * 512 = 512 bytes
				Sector size (logical/physical): 512 bytes / 512 bytes
				I/O size (minimum/optimal): 512 bytes / 512 bytes
				Disk identifier: 0x000ee7d2

				Device Boot      Start         End      Blocks   Id  System
				/dev/sda1   *        2048     1026047      512000   83  Linux
				/dev/sda2         1026048    20971519     9972736   8e  Linux LVM
				/dev/sda3        20971520    21176319      102400   83  Linux
				/dev/sda4        21176320    21995519      409600    5  Extended
				/dev/sda5        21178368    21383167      102400   83  Linux
				/dev/sda6        21385216    21995519      305152   83  Linux
			}

			!!! ### Delete partitions by using the d command. Be careful to avoid deleting necessary existing partitions, as this may result in an unusable system.
		}

		20.3.4 Changing the Filesystem Type{

			# By default, the fdisk utility sets the filesystem type to Id 83 (Linux) for primary and logical partitions. For extended partitions, the Id should be 5 and should never be changed.

			in terminal{
				# To change the filesystem type, use the t command:
					Command (m for help): t
				# The fdisk utility will prompt for the number of the partition to be changed:
					Partition number (1-6): 6

				# Lastly, the user will be prompted to enter a hexadecimal value for the Id. In the following example output, the user enters a value of 82, which changes the partition Id to Linux swap/Solaris:
					Hex code (type L to list codes): 82

					Changed system type of partition 6 to 82 (Linux swap / Solaris)

				# While at the Hex Code prompt, the user can display a list of the hex codes that are available by typing the L character:
					Hex code (type L to list codes): L

					0  Empty           24  NEC DOS         81  Minix / old Lin bf  Solaris
					1  FAT12           39  Plan 9          82  Linux swap / So c1  DRDOS/sec (FAT-
					2  XENIX root      3c  PartitionMagic  83  Linux           c4  DRDOS/sec (FAT-
					3  XENIX usr       40  Venix 80286     84  OS/2 hidden C:  c6  DRDOS/sec (FAT-
					4  FAT16 <32M      41  PPC PReP Boot   85  Linux extended  c7  Syrinx
					5  Extended        42  SFS             86  NTFS volume set da  Non-FS data
					6  FAT16           4d  QNX4.x          87  NTFS volume set db  CP/M / CTOS / .
					7  HPFS/NTFS       4e  QNX4.x 2nd part 88  Linux plaintext de  Dell Utility
					8  AIX             4f  QNX4.x 3rd part 8e  Linux LVM       df  BootIt
					9  AIX bootable    50  OnTrack DM      93  Amoeba          e1  DOS access
					a  OS/2 Boot Manag 51  OnTrack DM6 Aux 94  Amoeba BBT      e3  DOS R/O
					b  W95 FAT32       52  CP/M            9f  BSD/OS          e4  SpeedStor
					c  W95 FAT32 (LBA) 53  OnTrack DM6 Aux a0  IBM Thinkpad hi eb  BeOS fs
					e  W95 FAT16 (LBA) 54  OnTrackDM6      a5  FreeBSD         ee  GPT
					f  W95 Ext'd (LBA) 55  EZ-Drive        a6  OpenBSD         ef  EFI (FAT-12/16/
					10  OPUS            56  Golden Bow      a7  NeXTSTEP        f0  Linux/PA-RISC b
					11  Hidden FAT12    5c  Priam Edisk     a8  Darwin UFS      f1  SpeedStor
					12  Compaq diagnost 61  SpeedStor       a9  NetBSD          f4  SpeedStor
					14  Hidden FAT16 <3 63  GNU HURD or Sys ab  Darwin boot     f2  DOS secondary
					16  Hidden FAT16    64  Novell Netware  af  HFS / HFS+      fb  VMware VMFS
					17  Hidden HPFS/NTF 65  Novell Netware  b7  BSDI fs         fc  VMware VMKCORE
					18  AST SmartSleep  70  DiskSecure Mult b8  BSDI swap       fd  Linux raid auto
					1b  Hidden W95 FAT3 75  PC/IX           bb  Boot Wizard hid fe  LANstep
					1c  Hidden W95 FAT3 80  Old Minix       be  Solaris boot    ff  BBT
					1e  Hidden W95 FAT1



					# ------------------------------------------------------------------------------

					# In the following example, the /dev/sda6 partition is changed to 82, a swap partition, using the same steps described above.
						Command (m for help): t
						Partition number (1-6): 6
						Hex code (type L to list codes): 82
						Changed system type of partition 6 to 82 (Linux swap / Solaris)

					# It is always a good idea to double-check the new Id by printing the partition table:
						Command (m for help): p

						Disk /dev/sda: 11.3 GB, 11261706240 bytes
						255 heads, 63 sectors/track, 1369 cylinders, total 21995520 sectors
						Units = sectors of 1 * 512 = 512 bytes
						Sector size (logical/physical): 512 bytes / 512 bytes
						I/O size (minimum/optimal): 512 bytes / 512 bytes
						Disk identifier: 0x000ee7d2

						Device Boot      Start         End      Blocks   Id  System
						/dev/sda1   *        2048     1026047      512000   83  Linux
						/dev/sda2         1026048    20971519     9972736   8e  Linux LVM
						/dev/sda3        20971520    21176319      102400   83  Linux
						/dev/sda4        21176320    21995519      409600    5  Extended
						/dev/sda5        21178368    21383167      102400   83  Linux
						/dev/sda6        21385216    21995519      305152   82  Linux swap / Solaris
			}
		}

		20.3.5 Saving Changes{
			# If the changes that have been made to the in-memory partition table are correct, commit changes to disk with w, followed by Enter. The fdisk utility will write the in-memory changes to the actual MBR and exit. However, it is also possible to quit the fdisk utility without making any changes to the disk by using the q command.

			# Note the following possible error after saving changes ( in terminal):{
				The partition table has been altered!

				Calling iotctl() to re-read partition table.

				WARNING: Re-reading the partition table failed with error 16: Device or resource busy.
				The kernel still uses the old table. The table will be used at the next reboot or after you run partprobe(8) or kpartx(8)
				Syncing disks.
			}

			# This error is the result of the kernel being unable to read the new partition table into memory from the MBR, something that the ioctl() function is responsible for. As mentioned in the output of this error, the partprobe or kpartx command can be executed to fix this issue if these commands are installed on the system. If not, then the system will need to be rebooted before the new partitions can be used.
		}

		20.3.6 The sfdisk Command{
			# There is a scriptable fdisk-like program called sfdisk. Not only can this program be used to automate partitioning, it is also capable of backing up and restoring the current partition table.

			# To back up the partition table, first, determine the names of the disk devices. The sfdisk command will list the disk(s) and their sizes when provided the -s option. If the system contained only one 500 GB disk, then the output of the command may appear something like the following, with the pathname of the device and its size:

			in terminal{
				root@localhost:~# sfdisk -s
				/dev/sda:   500088608

				# ----------------------------------------------
				
				# Before partitioning the disk, it would be a good idea to back up the current partition table data by using the -d option to the sfdisk command:
				
				root@localhost:~# sfdisk -d /dev/sda > sda.disk

				# In the event that a mistake is made while using partition editing tools, the partition table can be restored to the original partition table by executing the sfdisk command with the -f option:

				root@localhost:~# sfdisk -f /dev/sda < sda.disk

				# Beware that using the wrong file may corrupt the partition table, which could result in a total loss of data.
			}
		}

		20.4 Managing GPT{
			# Some hard drives make use of a partitioning technology called Master Boot Record (MBR) while others make use of a partitioning type called GUID Partitioning Table (GPT). The MBR type of partitioning has been used since the early days of the personal computer (PC), and the GPT type has been available since the year 2000.

			# The GPT disks use a newer type of partitioning, which allows the user to divide the disk into more partitions than what MBR supports. GPT also allows having partitions, which can be larger than two terabytes (MBR does not). The tools for managing GPT disks are named similarly to the fdisk counterparts: the gdisk, cgdisk, and sgdisk programs.
		}

		20.4.1 Managing GPT{
			To create and manage GPT partitions from the command line, you can use the gdisk utility, also called GPT fdisk. It operates in a similar fashion to fdisk except it operates on GPT partitions and requires the device to be specified in order to work.

			in terminal{
				sysadmin@localhost:~$ sudo gdisk /dev/sdb1
				GPT fdisk (gdisk) version 1.0.3

				Partition table scan:
				MBR: not present
				BSD: not present
				APM: not present
				GPT: not present

				Creating new GPT entries.

				Command (? for help): ?
				b	back up GPT data to a file
				c	change a partition's name
				d	delete a partition
				i	show detailed information on a partition
				l	list known partition types
				n	add a new partition
				o	create a new empty GUID partition table (GPT)
				p	print the partition table
				q	quit without saving changes
				r	recovery and transformation options (experts only)
				s	sort partitions
				t	change a partition's type code
				v	verify disk
				w	write table to disk and exit
				x	extra functionality (experts only)
				?	print this menu
			}

			### When you specify a blank disk, it will scan the device and report back no partition information. Typing a question mark ? character returns a list of command options available, type n to add a new partition.

			in terminal{
				Command (? for help): n
				Partition number (1-128, default 1):
				First sector (34-62529502, default = 2048) or {+-}size{KMGTP}:
				Last sector (2048-62529502, default = 62529502) or {+-}size{KMGTP}:
				Current type is 'Linux filesystem'
				Hex code or GUID (L to show codes, Enter = 8300):
				Changed type of partition to 'Linux filesystem'
			}

			### It returns information about the new partition that was just created; you can also type p to print the partition table information.

			in terminal{
				Command (? for help): p
				Disk /dev/sdb1: 62529536 sectors, 29.8 GiB
				Sector size (logical/physical): 512/512 bytes
				Disk identifier (GUID): 78F1C87E-5159-4AD8-89BA-A5F79B854835
				Partition table holds up to 128 entries
				Main partition table begins at sector 2 and ends at sector 33
				First usable sector is 34, last usable sector is 62529502
				Partitions will be aligned on 2048-sector boundaries
				Total free space is 2014 sectors (1007.0 KiB)

				Number Start (sector) End (sector) Size Code Name
				1 2048 62529502 29.8 GiB 8300 Linux filesystem
			}

			### The v command will verify the partition to ensure it is free from errors.

			in terminal{
				Command (? for help): v

				No problems found. 2014 free sectors (1007.0 KiB) available in 1
				segments, the largest of which is 2014 (1007.0 KiB) in size.
			}

			### The o command allows you to create a new empty partition; it verifies that you want to delete existing partitions before proceeding.

			in terminal{
				Command (? for help): o
				This option deletes all partitions and creates a new protective MBR.
				Proceed? (Y/N): y
			}

			### The p command again prints information about the new partition.

			in terminal{
				Command (? for help): p
				Disk /dev/sdb1: 62529536 sectors, 29.8 GiB
				Sector size (logical/physical): 512/512 bytes
				Disk identifier (GUID): 4876B7C5-0ADB-4281-AA77-A3FFAEC5F2AF
				Partition table holds up to 128 entries
				Main partition table begins at sector 2 and ends at sector 33
				First usable sector is 34, last usable sector is 62529502
				Partitions will be aligned on 2048-sector boundaries
				Total free space is 62529469 sectors (29.8 GiB)

				Number Start (sector) End (sector) Size Code Name
			}

			### The w command writes the partition data to the disk and will exit. Once again, it verifies that you want to proceed with overwriting (deleting) the existing partitions.

			in terminal{
				Command (? for help): w

				Final checks complete. About to write GPT data. THIS WILL OVERWRITE EXISTING
				PARTITIONS!!

				Do you want to proceed? (Y/N): y
				OK; writing new GUID partition table (GPT) to /dev/sdb1.
				Warning: The kernel is still using the old partition table.
				The new table will be used at the next reboot or after you
				run partprobe(8) or kpartx(8)
				The operation has completed successfully.
			}
		}

		20.5 GNU Parted{
			# So far, you have learned to use the fdisk and gdisk commands to create, list, and delete partitions. Another available tool for creating and resizing partitions on a hard drive is the GNU Parted program. The GNU Parted program includes the parted command line tool and the gparted graphical interface tool. One benefit of using GNU Parted is that unlike the gdisk and fdisk tools, which are destructive partitioners, GNU Parted will non-destructively resize a partition as well as the filesystem on top of it.

			# The parted program can be used in two ways: command line mode and interactive mode. When using parted in either mode, a device must be specified. To do this, the following syntax must be used:

			syntax{
				parted DEVICE
			}

			# The DEVICE argument is used to specify the hard drive to modify, for instance, /dev/sdb. If this argument is not used, a default device will be chosen for you, or an error message may be displayed. To use parted in command line mode, the DEVICE argument must be followed by options to create or modify a partition. To see a list of options available for parted, use the --help option:

			in terminal{
				root@localhost:~# parted --help
				Usage: parted [OPTION]... [DEVICE [COMMAND [PARAMETERS]...]...]
				Apply COMMANDs with PARAMETERS to DEVICE.  If no COMMAND(s) are given, run in
				interactive mode.

				OPTIONs:
				-h, --help                      displays this help message
				-l, --list                      lists partition layout on all block devices
				-m, --machine                   displays machine parseable output
				-s, --script                    never prompts for user intervention
				-v, --version                   displays the version
				-a, --align=[none|cyl|min|opt]  alignment for new partitions

				COMMANDs:
				align-check TYPE N                        check partition N for TYPE(min|opt)
						alignment
				help [COMMAND]                           print general help, or help on
						COMMAND
				mklabel,mktable LABEL-TYPE               create a new disklabel (partition
						table)
				mkpart PART-TYPE [FS-TYPE] START END     make a partition
				name NUMBER NAME                         name partition NUMBER as NAME
				print [devices|free|list,all|NUMBER]     display the partition table,
						available devices, free space, all found partitions, or a particular partition
				quit                                     exit program
				rescue START END                         rescue a lost partition near START
						and END
				resizepart NUMBER END                    resize partition NUMBER
				Output Omitted...
			}

			# To view the disks on the system, use the lsblk command:

			in terminal{
				root@localhost:~# lsblk
				NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
				sda    8:0    0 3.7T  0 disk
				|-sda1 8:1    0 512M  0 part
				|-sda2 8:2    0 3.5T  0 part /etc/hosts
				`-sda3 8:3    0 128G  0 part [SWAP]
				sdb   8:16    0 20G  0  disk
			}

			# The sdb disk noted in the output above is the target device for the partitioning examples below. It is an empty disk that is the second device on the IDE device bus.

			# Next, to view any existing partition information with the parted command, use the following:

			in terminal{
				root@localhost:~# parted /dev/sdb print
				Model: ATA VMware Virtual I (scsi)
				Disk /dev/sdb: 21.5GB
				Sector size (logical/physical): 512B/512B
				Partition Table:
				Disk Flags:

				Number  Start  End  Size  Type  File system  Flags
			}

			# To make the disk partitionable, a disklabel (partition table) must be created. This is done with the following command:

			in terminal{
				root@localhost:~# parted /dev/sdb mklabel msdos
				You may need to update the /etc/fstab
			}

			### ## If a disk has an existing partition table, the command may query the user about overwriting the current partition table, and in that case, the user would type the Y key and then press Enter.

			# Now that a partition table is written to the disk, partitions can be created on the disk. To create a primary partition that takes up the first 50% of the disk, use the following command:

			in terminal{
				root@localhost:~# parted /dev/sdb mkpart primary 0% 50%
				You may need to update the /etc/fstab
			}

			# Once the command executes, the user can verify the partition was created with the command:

			in terminal{
				root@localhost:~# parted /dev/sdb print
				Model: ATA VMware Virtual I (scsi)
				Disk /dev/sdb: 21.5GB
				Sector size (logical/physical): 512B/512B
				Partition Table:
				Disk Flags:

				Number  Start    End      Size    Type     File system  Flags
				1       1049kB   10.7GB   10.7GB  primary
			}

			# While it is possible to format the resulting partition with a filesystem during the parted mkpart process, experience has indicated that the partitioning process is best done by parted and the creation of a filesystem by the appropriate mkfs command.

			# The parted utility’s interactive mode can also be used to create or resize partitions. To begin using interactive mode, simply use the parted command with a device argument to specify the drive:

			in terminal{
				root@localhost:~# parted  /dev/sdb
				GNU Parted 3.2
				Using /dev/sda
				Welcome to GNU Parted! Type ‘help to view a list of commands.
				(parted)
			}

			# Note in the example above that the prompt will change to (parted). The h command will display a menu or help screen:

			in terminal{
				(parted) h
				align-check TYPE N                       check partition N for TYPE(min|opt) alignment
				help [COMMAND]                           print general help, or help on COMMAND
				mklabel,mktable LABEL-TYPE               create a new disklabel (partition table)
				mkpart PART-TYPE [FS-TYPE] START END     make a partition
				name NUMBER NAME                         name partition NUMBER as NAME
				print [devices|free|list,all|NUMBER]     display the partition table, available devices,
				free space, all found partitions, or a particular partition
				quit                                     exit program rescue START END rescue a lost
				partition near START and END
				resizepart NUMBER END                    resize partition NUMBER
				rm NUMBER                                delete partition NUMBER
				select DEVICE                            choose the device to edit
				disk_set FLAG STATE                      change the FLAG on selected device
				disk_toggle [FLAG]                       toggle the state of FLAG on selected device
				set NUMBER FLAG STATE                    change the FLAG on partition NUMBER
				toggle [NUMBER [FLAG]]                   toggle the state of FLAG on partition NUMBER
				uni5 UNIT				      set the default unit to UNIT
				version				      display the version number and copyright information of Gnu Parted
			}

			## Notice that many of the commands used in command line mode such as the mkpart, mklabel, and print commands are available in the interactive mode. The process of creating and modifying partitions using parted in interactive mode is similar to using fdisk or gdisk in interactive mode.
		}

		20.6 Logical Volume Management{
			# Logical Volume Management (LVM) is a method of managing hard disk space that provides more flexibility than traditional partitioning of disks. LVM was developed specifically to address some of the limitations of traditional partitioning
		}

		20.6.1 LVM Concepts{
			# The steps to implement LVM include the following:

				1. Connect the physical devices to the system.

				2. Use pvcreate to convert the desired devices into physical volumes, which will allocate them for inclusion in the LVM scheme. This will write a header to the physical device and make them visible to the LVM process.

				3. Use vgcreate to incorporate all of the desired physical volumes into a virtual collection called a volume group. The volume group now will act as a multi-disk equivalent of a physical volume on which partitioning can occur.
				
				4. Use lvcreate to create the LVM version of disk partitions (called logical volumes) in the volume group created previously. The logical volumes act like partitions in that the user can create filesystems on them, mount them, and in general use them as a traditional partition.

			# At this point, they are just three hard drives that don't have anything on them, including a partition table. To use these as part of LVM, first execute the pvcreate command on each one:

			in terminal{
				root@localhost:~# pvcreate /dev/sdb
				root@localhost:~# pvcreate /dev/sdc
				root@localhost:~# pvcreate /dev/sdd
			}

			# Initially, these hard drives won't appear to be any different. However, there is now a small block of data, called a header, in the very beginning of each that defines each device as a physical volume.

			# The next step is to create a volume group that consists of these three physical volumes. This can be accomplished with the following command:

			in terminal{
				root@localhost:~# vgcreate vol1 /dev/sdb /dev/sdc /dev/sdd
			}

			# Any of the space in the vol1 volume group can be used to create a logical volume with a command like the following:

			in terminal{
				root@localhost:~# lvcreate -L 200M -n logical_vol1 vol1
			}

			# The -L option is used to specify the size of the logical volume. The value of 200M means create a 200MB logical volume. The -n option is used to provide a name to the logical volume. The resulting name of the logical volume created by the previous command will be logical_vol1. The last argument, vol1, is the name of the volume group from where the logical volume will obtain its physical space. The previous lvcreate command would result in a new device name of /dev/vol1/logical_vol1 that could be used just like a traditional partition.
		}

		20.7 Creating a Filesystem{
			# If the fdisk command is used to create a partition, then the filesystem will have to be created separately.

			# The mkfs command can be used to create a filesystem. To make a vfat type filesystem, which is compatible with multiple operating systems, including Microsoft Windows, execute the command like the following:

			in terminal{
				root@localhost:~# mkfs -t vfat /dev/sdb1
			}

			# The mkfs command is a wrapper that executes another command, which will actually make the correct filesystem. When provided the -t vfat option, the mkfs command will call the mkdosfs command to make the actual filesystem. This is important to know because the mkfs command provides generic options while the underlying command may have options specific to the filesystem that it creates. Consult the documentation, such as the man pages, to see these additional options.

			# A very common filesystem is the Fourth Extended Filesystem, ext4, the default filesystem on many Linux distributions. To create this type of filesystem, execute a command like the following:

			in terminal{
				root@localhost:~# mkfs -t ext4 /dev/sdb1
			}

			# For example, the mke2fs command has several options that will modify how the filesystem will behave after it has been created. Some of these features can be changed after the filesystem has been created, but others cannot. The following table describes a few of the common features that a system administrator may change for ext2/etx3/ext4 filesystems:

				Option 		Description
				-b 			Specifies the block size of the filesystem. While the default is typically fine for normal filesystems, for filesystems with large databases, a larger block size is more ideal.
				
				-N 			Specifies the number of inodes. Recall that each file needs an inode, so this value is an important one. By default, the mke2fs command uses a formula based on filesystem size to determine how many inodes to create.
							Typically, this generates a huge number of inodes, which on filesystems with only a handful of large files results in wasted spaces since these inodes take space even if they are not in use.
							The number of inodes can't easily be changed after the filesystem has been created.
				
				-m 			Specifies what percentage of the filesystem is reserved for system use. Consider the partial output of the df command shown below:
							in terminal{
								Filesystem  Size  Used  Avail Use% Mounted on
								/dev/sda2   485M  114M  346M  25%  /
							}
							There appears to be something wrong with this output. If 114M of a 485M filesystem is used, then there should be 368M available, not 346M! Also, the Use%, which displays how much space has been used, is inaccurate. It should be closer to 23%.
							The reason why these numbers are inaccurate is that 5% of the filesystem is reserved for system use. Regular users can't use this space, so it is considered to be unavailable; as a result, the df command takes that into consideration when reporting available space.
							To specify a different percentage of reserved space, use the -m option. This is a useful option for filesystems that the root user doesn't typically use, like the /home filesystem.
		}

		20.8 exFAT{
			# From the command line, you will need to make sure the proper repository, in this case, the universe repository, is installed. To ensure that the repository is installed, the add-apt command can be used. In the example below, the output of the add-apt command establishes that the repository is already present on the system. However, if it was not, the add-apt command could be used to install it:
			
			in terminal{
				sysadmin@localhost:~$ sudo add-apt-repository universe
				[sudo] password for sysadmin:
				'universe' distribution component is already enabled for all sources.
			}

			## A repository is a collection of data stored on a server. In Linux, repositories are used to store system updates and applications that can be downloaded.
				The add-apt command is part of the Advanced Package Tool (APT) used for package management.

				Repositories and package management are covered in greater detail later in the course.
			
			# Next, the apt update command can be used to confirm that everything in the repository is up-to-date:

			in terminal{
				sysadmin@localhost:~$ sudo apt update
				Hit:1 http://us.archive.ubuntu.com/ubuntu cosmic InRelease
				Get:2 http://us.archive.ubuntu.com/ubuntu cosmic-updates InRelease [88.7 kB]
				Get:3 http://us.archive.ubuntu.com/ubuntu cosmic-security InRelease [88.7 kB]
				Hit 4: http://us.archive.ubuntu.com/ubuntu cosmic-backports InRelease
				Fetched 177 kB in 1s (139 kB/s)
				Reading package lists… Done
				Building dependency tree
				Reading state information… Done
				11 packages can be upgraded. Run ‘apt list —upgradable’ to see them.
			}
		}

		20.9 BTRFS{
			# BTRFS (sometimes pronounced b-tree FS or butter FS) is a Linux native filesystem created by Oracle and developed by multiple companies as well as many individual contributors to address the limitations of previous filesystems.
		
			Copy-On-Write{
				# BTRFS is a copy-on-write (COW) system. While a complex technical feature, the main point of copy on write is that BTRFS will not overwrite an existing file with updates, which traditional non-COW filesystems do routinely.
			
				# For example, if you have a file named datafile1.txt and you make updates to the file’s contents, on a traditional non-COW filesystem, the file would be overwritten with the new data, making retrieval of the original version of the file something that could only be done by restoring from backup. Instead of BTRFS overwriting datafile1.txt, it will leave that file in place, untouched, and writes the new or changed portions of the file elsewhere, and then changes the file’s metadata to encompass the change.

				# Copy-on-write is one reason why BTRFS has a significant advantage of recovery time from hardware failure, power outage, or other forms of catastrophe. The original version of the file will remain intact, and continue to be available even as follow-on versions or changes are written elsewhere. This has the added benefit of acting as a journal of sorts because transactions (updates) are either completed or not, and if not, the already written to disk portions of the file are safe and sound on disk.
			}
		}

		20.10 Creating Swap Space{
			There are two types of swap spaces that can be created:{	

				1. Swap Partition: The more common of the two, a swap partition is a partition that doesn't have a regular filesystem on it, and is not mounted. During installation, a swap partition is created, but additional swap partitions can be created at a later time.

				2. Swap File: In the event that there is no unpartitioned space left on the hard drive, a swap file can be used. Swap partitions are typically faster than swap files as they are a filesystem, not a file, that is located on top of another filesystem. Swap files are more flexible and can be created on the fly without the need to repartition the hard drive.

			}
		}

		20.10.1 Creating a Swap Partition{
			The steps to creating a swap partition are:{
				1. Create a partition with an Id of 82 using fdisk as previously described:
					in terminal{
						Command (m for help): n
						Command Action
						e   extended
						p   primary partition (1-4)
						p
						Partition number (1-4): 3
						First sector (20971520-21995519, default 20971520):
						Using default value 20971520
						Last sector, +sectors, or +size{K,M,G} (20971520-21995519, default 21995519): +100

						Command (m for help): t
						Partition number (1-6): 3
						Hex code (type L to list codes): 82
						Changed system type of partition 3 to 82 (Linux swap / Solaris)
					}

				2. Convert the partition to swap space with the mkswap command.
					in terminal{
						root@localhost:~# mkswap /dev/sda3
						Setting up swapspace version1, size = 102396 KiB
						no label, UUID=59aaf06e-7109-471f-88a5-e81dd7c82d76
					}
				
				3. Enable the partition as current swap space with the swapon command:
					in terminal{
						root@localhost:~# swapon /dev/sda3
					}
			}

			### The -s option to the swapon command will display currently used swap space:

			in terminal{
				root@localhost:~# swapon -s
				Filename                                Type            Size    Used    Priority
				/devdm-1                                partition       1015800 0       -1
				/dev/sda3                               partition       102392  0       -2
			}
		}

		20.10.2 Creating a Swap File{
			The steps to create a swap file:{
				1. Create a large file using the dd command. In order to determine which filesystem has room for the swap file, the df command was executed. The / filesystem has plenty of room, so the swap file was placed in the /var directory:
					in terminal{
						root@localhost:~# df -h
						Filesystem      Size  Used Avail Use% Mounted on
						/dev/sda9        58G  7.7G   49G  14%
						tmpfs           7.9G     0  7.9G   0% /dev
						shm              64M     0   64M   0% /dev/shm
						/dev/sda9        58G  7.7G   49G  14% /etc/hosts
						root@localhost:~# dd if=/dev/zero of=/var/extraswap bs=1M count=100
						100+0 records in
						100+0 records out
						104857600 bytes (105 MB) copied, 0.320096 s, 328 MB/s
					}
					# Note that the resulting file is approximately 100MB in size, 100 blocks of 1MB in size. The options bs=100M and count=1 would have resulted in the same size. The file is full of binary zero values that came from the /dev/zero file. What is actually in the file doesn't really matter; the size of the file is what is important.
			
				2. Convert the file to swap space with the mkswap command:
					in terminal{
						root@localhost:~# mkswap /var/extraswap
						Setting up swapspace version 1, size = 102396 KiB
						no label, UUID=908e51f8-a022-4508-8819-73e1d8837e2b
					}
				
				3. Enable the file as current swap space with the swapon command:{
					root@localhost:~# swapon /var/extraswap
					root@localhost:~# swapon -s
					Filename                                Type            Size    Used    Priority
					/devdm-1                                partition       1015800 0       -1
					/dev/sda3                               partition       102392  0       -2
					/var/extraswap                          file            102392  0       -3
				}
			}
		}

		key terms{

			fdisk
				Command used to manipulate the MBR partition table for Linux. This utility can be used to create, modify, and delete partitions for a fixed disk.
				Section 20.3 | Section 20.3.1 | Section 20.3.2 | Section 20.3.3 | Section 20.3.4 | Section 20.3.5 
			gdisk
				An interactive GPT partition table manipulator. It will automatically covert the old-style MBR partition toable to the GPT format.
				| Section 20.4 | Section 20.4.1 
			mke2fs
				Command used to create an ext2/ext3/ext4 filesystem. This usually corresponds to a device such as a hard drive.
				Section 20.7 
			mkfs
				Command used to build a Linux file system on a device. mkfs.fstype is also available to create a specific file system with ease. For example an adminsitrator can use mkfs.ext4 to build an ext4 file system.
				Section 20.7 
			mkswap
				Command used to build a Linux swap area. A device argument will be need to specify where the swap area will be created.
				Section 20.10.1 | Section 20.10.2 
			parted
				A disk partitioning and partition resizing utility. It allows an administrator to destroy, create, resize, move, and copy ext2, linux-swap, FAT, and FAT32.
				Section 20.5 
			swap space
				Used when the amount of physical memory (RAM) is full. If the system needs more memory resources and the RAM is full, inactive pages in memory are moved to the swap space.
				| Section 20.10 | Section 20.10.1 | Section 20.10.2 
		}
	}
}
chapter 21{
	21.2 Viewing Mounted Filesystems{
		# Mounting of partitions and checking on existing mounts is accomplished with the mount command. When called with no arguments, the mount command shows the currently mounted devices. This can be performed by regular users, not just the root user

		in terminal{
			sysadmin@localhost:~$ mount
			/dev/sda2 on / type ext4 (rw)
			proc on /proc type proc (rw)
			sysfs on /sys type sysfs (rw)
			devpts on /dev/pts type devpts (rw,gid=5,mode=620)
			tmpfs on /dev/shm type tmpfs (rw)
			/dev/sda1 on /boot type ext4 (rw)
			/dev/sda5 on /home type ext4 (rw)
			none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)
			sunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs
		}

		The general format of this output is:{
			DESCRIPTION OF SOURCE on MOUNT POINT type FILESYSTEM TYPE (OPTIONS)
		}

		Description of Source{
			{
				/dev/sda5 on /home type ext4 (rw)
				---------

				proc on /proc type proc (rw)
				----
			}
			# Every mounted filesystem comes from a source—either a device representing a disk, a network location for a network filesystem, or a tag indicating a pseudo-filesystem. This latter class (which includes proc, sysfs, devpts, tmpfs, none, and sunrpc in the output above) is the Linux kernel's way of sharing information with the real filesystem. For example, the proc filesystem exposes the process list and system configuration as a set of files that can be read and written to. 
		}

		Mount Point{
			{
				/dev/sda2 on / type ext4 (rw)
								-
				
				/dev/sda5 on /home type ext4 (rw)
								-----
			}
			# The mount point shows where the source can be found on the filesystem. The output above indicates that the root / filesystem is actually served from the /dev/sda2 partition, but files in the /home directory are stored on the /dev/sda5 partition.
		}

		Filesystem Type{
			{
				/dev/sda5 on /home type ext4 (rw)
										----
				
				proc on /proc type proc (rw)
									----
			}
			# Each filesystem has a type, which tells the kernel how to work with the data contained on the device. For actual filesystems like the xfs, ext4, and reisferfs filesystems, this relates the blocks stored on disk to the files and directories that you see. For network filesystems like the nfs filesystem, this translates the network calls and packets sent and received into disk reads and writes. For the pseudo-filesystems, the filesystem type describes what kind of resources are exposed.
		}

		Options{
			{
				/dev/sda5 on /home type ext4 (rw)
												----
				
				devpts on /dev/pts type devpts (rw,gid=5,mode=620)
												-------------------
			}
			# Each filesystem also has options. Some options, such as the read/write rw option and read-only ro option, are fairly universal. Some filesystems have options corresponding to specific items such as the network timeout parameters for a network filesystem or the journalling parameters for a journaled filesystem.

			# Administrators generally work with disk drives and network filesystems, leaving the pseudo filesystems for the distribution to set up and manage. The disks may take many forms such as individual disk partitions, logical disks made up of multiple disks (such as LVM), or even other hardware that presents itself as a disk (such as RAID).

			# Another method for getting information about filesystems is by using the lsblk command. The lsblk command lists information about block devices, either all of the ones that are available with the -a option, or output can be tailored with various other options such as the -f option, which outputs information about available filesystems.

			in terminal{
				sysadmin@localhost:/$ lsblk -a
				NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
				loop0    7:0    0        0 loop
				loop1    7:1    0        0 loop
				loop2    7:2    0        0 loop
				loop3    7:3    0        0 loop
				loop4    7:4    0        0 loop
				loop5    7:5    0        0 loop
				loop6    7:6    0        0 loop
				loop7    7:7    0        0 loop
				sda      8:0    0  3.7T  0 disk
				|-sda1   8:1    0  512M  0 part
				|-sda2   8:2    0  3.5T  0 part /etc/hosts
				`-sda3   8:3    0  128G  0 part [SWAP]
				sdb      8:16   1        0 disk
				sdc      8:32   1        0 disk
				sr0     11:0    1 1024M  0 rom
				sr1     11:1    1 1024M  0 rom
				sysadmin@localhost:/$ lsblk -f
				NAME   FSTYPE LABEL UUID MOUNTPOINT
				sda
				|-sda1
				|-sda2                   /etc/hosts
				`-sda3                   [SWAP]
				sr0
				sr1 
			}
		}
	}

	21.3 Mounting Filesystems Manually{
		# In order to properly mount a filesystem, at least two parameters must be provided to the mount command: the filesystem identifier and the directory path name to mount it on. If no other options are needed, the mount command will mount the filesystem on the specified directory mount point. 
		
		!!! Unless set up in the /etc/fstab file beforehand, mounting requires root user access.

		in terminal{
			root@localhost:~# mount /dev/sdb1 /mnt
		}
		# The first step to mounting a filesystem is to create a directory to serve as a mount point. Alternatively, the /mnt and /media directories may be used, which usually exist by default on most Linux distributions for this purpose. The /mnt and /media directories are typically only used to mount a temporary resource such as removable media, including USB drives and optical disks. Some desktop-oriented distributions will automatically mount removable devices under the /media/USERNAME/DEVICENAME directory.

		# The easiest form of the manual mount command is shown above. In this situation, the Linux kernel understands that /dev/sdb1 is a filesystem and can even detect what kind of filesystem is on the disk. If the filesystem cannot be detected, then use the -t option to indicate the type of filesystem:

		in terminal{
			root@localhost:~# mount -t iso9660 /dev/scd0 /mnt
		}
		# This last command mounts a device called /dev/scd0 on /mnt and tells the kernel to use the iso9660 filesystem, which is for CD and DVD devices. If it is necessary to tell the kernel what kind of filesystem is being used, then this should be a sign that something is amiss as the autodetection is generally reliable.

		# When a filesystem is mounted, the default options for that filesystem are used. The -o option can be used to specify alternative mount options from the command line. Some mount options are only used when manually mounting a filesystem, while others are commonly used when automatically mounting a filesystem.

		# To mount a filesystem read-only, pass the ro option, such as
		in terminal:{
			root@localhost:~# mount /dev/sdb2 /opt -o ro
		}

		Consider This{
			# Mounting a filesystem on a directory that already contains files will render those files temporarily inaccessible. Therefore be careful to mount on directories known to be empty.

			# Once a filesystem is mounted on a directory, only the contents of that filesystem will be visible. What was previously visible in a directory is not gone, but will become visible only after the new filesystem is unmounted.

			# For example, consider the situation in which the /data directory already contains files and then it is used as a mount point:
			in terminal{
				root@localhost:~# ls /data
				file1 file2
				root@localhost:~# mount /dev/sda3 /data
				root@localhost:~# ls /data
				file3 file4
			}

			# It appears that file1 and file2 were deleted, but they are just hidden from view. If the filesystem was unmounted, then these files would reappear:
			in terminal{
				root@localhost:~# ls /data
				file3 file4
				root@localhost:~# umount /data
				root@localhost:~# ls /data
				file1 file2
			}
		}
	}

	21.4 Unmounting Filesystems Manually{
		# To maximize performance, Linux keeps parts of the filesystem in memory. If media, such as USB devices, were to be removed before those memory buffers were flushed, some data may not be written to disk. This is known as an “unclean” dismount. This may result in data loss or even filesystem corruption. Unmounting is the procedure used to flush all the buffers and make the disk safe to remove.

		# To unmount a filesystem, use the umount command with either the filesystem or the directory given as an argument. For example, to unmount the /mnt directory that was previously mounted, execute the following command:
		in terminal{
			root@localhost:~# umount /mnt

			# Because the /dev/sdb1 filesystem was mounted under the /mnt directory, the following command would have also worked:

			root@localhost:~# umount /dev/sdb1
		}

		# There are a few instances where the umount command will fail to unmount a filesystem:
		
			1. There is a file open that is located within the filesystem. The term open meaning in use by a program. For example, if the file was being edited by a text editor like the vi editor, it would be considered to be open.

			2. There is an executable file running that is located within the filesystem.

			3. A user has a directory within the filesystem as their current working directory.
		
		# When the umount command fails to unmount a filesystem, it will normally report that the device is busy
		in terminal{
			root@localhost:~# umount /mnt
			umount: /mnt: device is busy.
				(In some cases useful info about processes that use
				the device is found by lsof(8) or fuser(1))
		}
		# To determine what is making the filesystem busy, use the lsof or fuser commands

		# The output of the lsof command is the list of all open files on the operating system, which can easily number in the thousands. Therefore, it is important to filter the output of the lsof command to find the correct opened file. A good way to do this is to pipe the output of the lsof command to the grep command. Use the grep command to find the filesystem that should be unmounted. For example, if the /mnt directory was busy, the root user can execute the following command from the /mnt directory:
		in terminal{
			root@localhost:/mnt# lsof | grep /mnt
			bash      2577      root  cwd       DIR        8,1     1024          2 /mnt
			lsof      2631      root  cwd       DIR        8,1     1024          2 /mnt
			grep      2632      root  cwd       DIR        8,1     1024          2 /mnt
			lsof      2633      root  cwd       DIR        8,1     1024          2 /mnt
		}
		# The first three columns are most useful: the name of the process, the process ID, and the user running the process. Using the process ID along with the kill command, a system administrator can terminate processes that may be keeping the directory busy
		!!!! However, be very careful about killing processes that have files open for writing as this may damage files or directories within a filesystem.

		## The fuser command provides much more concise output, and it will indicate if a file is open for writing. It is even able to terminate processes, much like the kill command.
	
		## ### The -v option to the fuser command produces slightly more output, including the name of the user who is running the process and a code which indicates the way that a process is using the directory. For example, if unsuccessfully attempting to unmount the /mnt directory, try executing the following fuser command:
		in terminal{
			root@localhost:~# fuser -v /mnt
									USER        PID ACCESS COMMAND
				/mnt:                root       2529 ..c.. bash
		}
		# In this case, the process keeping the /mnt directory busy is being run by the root user. The process id is 2529, the access of c indicates the process is using the directory as its current directory. The process itself is the Bash shell.

		# Access codes that might be reported by the fuser command are:
			Access Code 	Meaning
			c 				The process is using the mount point or a subdirectory as its current directory.
			e 				The process is an executable file that resides in the mount point structure.
			f 				The process has an open file from the mount point structure.
			F 				The process has an open file from the mount point structure that it is writing to.
			r 				The process is using the mount point as the root directory.
			m 				The process is a mmap'ed file or shared library.

		# If the process has a file open for writing or the mount point is a root directory, it is not wise to kill that process. Otherwise, to terminate the process, execute the following command:
		in terminal{
			root@localhost:~# fuser -k /mnt
		}

		# As with the kill command, the default signal sent by the fuser command is the TERM signal. Use the fuser -l command to list the signals that can be used:
		in terminal{
			root@localhost:~# fuser -l
			HUP INT QUIT ILL TRAP ABRT IOT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM STKFLT CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH IO PWR SYS
		}

		# These are the same signals that are available for the kill command. To send a specific signal with the fuser command, place a hyphen in front of the signal name. For example, to end a stubborn process that is keeping the /mnt directory busy, execute the following command:
		in terminal{
			root@localhost:~# fuser -k -KILL /mnt
		}
		# Once the process has been terminated, it should be possible to execute the umount command to unmount the filesystem
	}

	21.5 Mounting Filesystems Automatically On Boot{
		# Manually mounting filesystems with the mount command results in a non-persistent mount. If the system is rebooted, then the filesystem must be mounted again to be accessed. The same is true for activating swap devices with the swapon command.
		!!! # Root privileges are required to make changes to the /etc/fstab file. Any changes made to this file should be performed with care, as mistakes may prevent the system from booting normally.

		# In fact, it would be an excellent idea to create a backup of the /etc/fstab file before making changes. In the event of a disaster, the original file can be restored by copying the backup to the /etc/fstab file using a recovery of a live disk. To make a backup copy, as the root user, execute a command like the following:
		in terminal{
			root@localhost:~# cp /etc/fstab /etc/fstab.backup

			output{
				#
				# /etc/fstab
				# Created by anaconda on Fri Jan 17 10:31:51 2014
				#
				# Accessible filesystems, by reference, are maintained under '/dev/disk'
				# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info
				#
				UUID=3db6ba40-67d2-403d-9c0a-9a901697cd8d /      ext4    defaults        1 1
				UUID=09d641d5-bc5a-4065-8d80-8ae797dfa7f3 /boot  ext4    defaults        1 2
				UUID=5ee634a5-c360-4211-a41b-9aa40d78a804 /home  ext4    defaults        1 2
				UUID=34819281-65e3-4c78-ba2d-16952684c9cb swap   swap    defaults        0 0
				tmpfs                   /dev/shm                tmpfs   defaults        0 0
				devpts                  /dev/pts                devpts  gid=5,mode=620  0 0
				sysfs                   /sys                    sysfs   defaults        0 0
				proc                    /proc                   proc    defaults        0 0
			}
		}

		# Notice that the first seven lines of this file are comments because they start with the # character. To add comments to the file, start a line with a # character. The existing comments recommend referring to man pages for the fstab, findfs, mount, and blkid commands.

		Device Identifier{
			# The first column identifies the device to be mounted. This could be the name of a device like /dev/sdb1 in the previous manual mount examples. However, the /etc/fstab file is read at boot time when the system is unattended, so it is not always possible to predict the name of the devices. For example, if SATA cables are switched during maintenance, the /dev/sda device may change places with the /dev/sdb device.

			UUID{
				# For this reason, the most common way to refer to a partition is by using a universally unique identifier (UUID), as in the following example:
				{
					UUID=3db6ba40-67d2-403d-9c0a-9a901697cd8d /      ext4    defaults        1 1
					-----------------------------------------

					UUID=09d641d5-bc5a-4065-8d80-8ae797dfa7f3 /boot  ext4    defaults        1 2
					-----------------------------------------

					UUID=5ee634a5-c360-4211-a41b-9aa40d78a804 /home  ext4    defaults        1 2
					-----------------------------------------
				}

				# To determine what the UUID value is for a device, use the blkid command. The output of this command will look similar to this, though the UUIDs will be different:
				in terminal{
					root@localhost:~# blkid
					/dev/sda1: UUID="09d641d5-bc5a-4065-8d80-8ae797dfa7f3" TYPE="ext4"
					/dev/sda2: UUID="3db6ba40-67d2-403d-9c0a-9a901697cd8d" TYPE="ext4"
					/dev/sda3: UUID="34819281-65e3-4c78-ba2d-16952684c9cb" TYPE="swap"
					/dev/sda5: UUID="5ee634a5-c360-4211-a41b-9aa40d78a804" TYPE="ext4"
					/dev/sdb1: UUID="a9183c2c-ee1f-4e57-9a60-b0d9e87a0337" TYPE="ext4"
					/dev/sdb2: UUID="71b38ae6-6824-4ad3-9e2f-821d7f532b97" TYPE="swap"
				}

				# The UUID is automatically created when the filesystem is created. It is considered the best way to identify local filesystems in the /etc/fstab file because it doesn't change after the filesystem has been created and it should always be unique. Even if the hard drive is moved to another computer, the UUIDs will be unique for each filesystem. Unfortunately, the UUID isn't easy to remember or type, so it is difficult to use for manual mounting.
			}

			Device Name{
				# A second, more traditional way of specifying a local filesystem is to use the path name for the device, such as /dev/sda1 for the first partition on the first disk:
				{
					/dev/sda1  /      ext4    defaults        1 1
					---------

					/dev/sda2  /boot  ext4    defaults        1 2
					---------

					/dev/sda5  /home  ext4    defaults        1 2
					---------
				}
			}

			Labels{
				# Another option is to use filesystem labels. The volume label can be set using the e2label command. For example, the following command will set a label called mydata on the /dev/sdb1 filesystem:
				in terminal{
					root@localhost:~# e2label /dev/sdb1 mydata
				}
				# The label for a filesystem can be viewed with the e2label command:
				in terminal{
					root@localhost:~# e2label /dev/sdb1
					mydata
				}

				# Labels can also be created for the extents filesystem xfs, either while making the filesystem or by using the xfs_admin command:
				in terminal{
					root@localhost:~# xfs_admin -L myapps /dev/sdb3
				}

				# Labels can be viewed (if they are set) with the blkid command just like they were for the UUIDs. The output of the blkid command is helpful, as it shows how to use the label:
				in terminal{
					root@localhost:~# blkid /dev/sdb1
					/dev/sdb1: UUID="a9183c2c-ee1f-4e57-9a60-b0d9e87a0337" TYPE="ext4" LABEL="mydata"
				}

				# Labels can be used in the first field of the /etc/fstab file, such as LABEL="mydata". If labels are created by a single administrator, unique labels can be ensured; however, multiple users with root access may accidentally create partitions with the same label name:
				{
					LABEL="root" /      ext4    defaults        1 1
					------------

					LABEL="boot" /boot  ext4    defaults        1 2
					------------

					LABEL="home" /home  ext4    defaults        1 2
					------------
				}

				!!!! Be careful with labels because they are human generated and can be duplicated when cloning a disk.

				# If the system detects a duplicate label, it is unpredictable which disk partition the system will actually mount when that label is used.
			}

			# The following table provides a summary of these three methods of referring to the partition to mount:
				Method 			Advantages 																													Disadvantages
				UUID 			Should always be unique, preventing any mounting conflicts. 																Hard to type and difficult to remember.
				Device Name 	Easy to type and remember. 																									Device names can easily change, causing mounting errors.
				Label 			Easy to type and remember. Label names won't dynamically change like device names, but they are not always unique. 			May not be unique like UUID naming.
	
		}

		Mount Point Field{
			# The second field is the mount point (mount directory) where the partition is to be mounted. It also corresponds to the second parameter to the mount command:
			{
				UUID=3db6ba40-67d2-403d-9c0a-9a901697cd8d /      ext4    defaults        1 1
				UUID=09d641d5-bc5a-4065-8d80-8ae797dfa7f3 /boot  ext4    defaults        1 2
				UUID=5ee634a5-c360-4211-a41b-9aa40d78a804 /home  ext4    defaults        1 2
			}
			# There is nothing special about a mount point, it is either an empty directory that was created with the mkdir command for that purpose or an existing directory.
		}

		Filesystem Field{
			# The third field is the filesystem type. Enter the correct Type Code using the values provided by the following table:
				Name 							Type Code
				Fourth Extended Filesystem 		ext4
				Third Extended Filesystem 		ext3
				Second Extended Filesystem 		ext2
				Extents Filesystem 				xfs
				File Allocation Table 			vfat
				ISO 9660 						iso
				Universal Disc Format 			udf

			
			# In most cases, the filesystem type for regular partitions will be the ext4 filesystem:
			{
				UUID=3db6ba40-67d2-403d-9c0a-9a901697cd8d /      ext4    defaults        1 1
																	----

				UUID=09d641d5-bc5a-4065-8d80-8ae797dfa7f3 /boot  ext4    defaults        1 2
																	----

				UUID=5ee634a5-c360-4211-a41b-9aa40d78a804 /home  ext4    defaults        1 2
																	----
			}
		}

		Mount Option Field{
			### # The fourth field in the /etc/fstab file is a comma-separated list of the mount options which would normally be passed to mount with the -o options. This field is used to pass parameters to the filesystem driver, such as to make the device read-only or to adjust timeouts. Most filesystems have a huge number of mount options available:
			{
				UUID=3db6ba40-67d2-403d-9c0a-9a901697cd8d /      ext4    defaults        1 1
																			--------

				UUID=09d641d5-bc5a-4065-8d80-8ae797dfa7f3 /boot  ext4    defaults        1 2
																			--------

				UUID=5ee634a5-c360-4211-a41b-9aa40d78a804 /home  ext4    defaults        1 2
																			--------
			}

			# Earlier in this chapter, it was mentioned that partitions could be mounted read-only. To prevent any changes to a filesystem, place the read-only mount option in the corresponding line of the /etc/fstab file:
			{
				UUID=3db6ba40-67d2-403d-9c0a-9a901697cd8d /date      ext4    ro        1 1
																				--
			}

			# The most common mount option is the defaults option. The defaults mount option implies a number of standard mount options are in effect. The following table lists the mount options that are in effect when defaults is used, the purpose of the mount option, and the option that is the opposite of the default mount option (if available):
				Mount Option 				Purpose 																																													Opposite
				rw 							Allow reading and writing 																																									ro
				suid 						Allow suid executes 																																										nosuid
				dev 						Allow device files 																																											nodev
				exec 						Allow executable files 																																										noexec
				auto 						Automatically mount 																																										noauto
				nouser 						Prevent ordinary users from mounting or unmounting the partition. Using the user option allows non-root users to mount that particular device, which is helpful for removable media. 		user
				async 						All writes should be asynchronous 																																							sync
				relatime 					Only update access time on file access if the file has been modified or its metadata changed since last access 																				N/A
		
			
			# The following configuration will still be mounted in read/write mode, allow executable files, and so forth:
			{
				UUID=3db6ba40-67d2-403d-9c0a-9a901697cd8d /date      ext4    nosuid,nodev   1 1
			}

			# It is interesting to note that when using defaults for the mount options, the only mount option that will be displayed when the mount command is executed will be the rw options:
			{
				UUID=3db6ba40-67d2-403d-9c0a-9a901697cd8d /      ext4    defaults        1 1
																							-

				UUID=09d641d5-bc5a-4065-8d80-8ae797dfa7f3 /boot  ext4    defaults        1 2
																							-

				UUID=34819281-65e3-4c78-ba2d-16952684c9cb swap   swap    defaults        0 0
																							-
			}

			# The purpose of this field is to tell an administrator which filesystems should be backed up when using the dump command. The administrator would execute the dump -w command and the resulting output would be a list of the filesystems to back up. This list is generated by filesystems that have a value of 1 in the dump field of the /etc/fstab file. A value of 1 in this field is used for local real filesystems (filesystems on partitions that reside on local hard drives). Any pseudo-filesystems, remote filesystems, or swap space entries should have a 0 value in this field.

			# This is a bit out of date, as the dump command is rarely used by system administrators on modern Linux distributions. However, it is important to know since the /etc/fstab file requires a valid entry in this field.
		}

		Filesystem Check Field{
			{
				UUID=3db6ba40-67d2-403d-9c0a-9a901697cd8d /      ext4    defaults        1 1
																							-

				UUID=09d641d5-bc5a-4065-8d80-8ae797dfa7f3 /boot  ext4    defaults        1 2
																							-

				UUID=34819281-65e3-4c78-ba2d-16952684c9cb swap   swap    defaults        0 0
																							-
			}
			# The sixth field is for determining the order in which the filesystems will be checked by the fsck (File System ChecK ) utility during system boot. This utility is designed to find and fix filesystem problems.
			# The root filesystem should always have a 1 in this field to indicate that it will be checked by the fsck program first. All other local filesystems (ext2/ext3/ext4) should have a value of 2 specified for this field, so they will be checked after the root filesystem.

			# Any pseudo-filesystems, remote filesystems, or swap space entries should have a 0 value in this field. These filesystems should never be checked by the fsck utility.
		}
	}

	21.6 Mounting With fstab{
		# There is a valuable mount option that will never be specified in the /etc/fstab file: the remount option. This option is useful for changing a mounted filesystem’s options without unmounting the filesystem itself.
		in terminal{
			root@localhost:~# mount /home -o remount, noatime
		}
		# This command will switch the /home mount to have the noatime option (the atime option shows the last time a file was accessed or read) without needing to remount the filesystem. Keep in mind that this will not persist across a reboot until the fstab file has been updated. Once changes have been made to the fstab file, execute something like the following to make them effective:
		in terminal{
			root@localhost:~# mount -o remount /mnt
		}

		# After updating the /etc/fstab file, don't reboot the system to test the changes. Instead, use the -o remount option. If the changes are correct, no message will be displayed, but if a mistake was made, an error like the following would be displayed:
		in terminal{
			root@localhost:~# mount -o remount /
			mount: / not mounted already, or bad option
		}
		# If there are no errors in the corresponding entry contained within the /etc/fstab file, then the mount -o command will produce no output.

		# The remount option is helpful but can lead to problems if the administrator allows the /etc/fstab file to get out of sync with the running configuration.
	}

	21.7 Systemd Mount Units{
		# Another approach to mounting filesystems is by using systemd mount units. Systemd mount units are configuration files that end in .mount and contain information about resources to be mounted at startup.

		# The systemd-mount utility is the mechanism that systemd uses to create and start a transient .mount file, destroy a transient .mount file, or to start an .automount unit of the filesystem.

		# The [Unit] field:
			{
				[Unit]

				Description=Mount unit for core, revision 6673
				
				Before=snapd.service
			}
			Field 				Purpose
			Description 		Shows which mount unit is going to be mounted.
			Before 				Shows the snapd.service file as the file name to be mounted.
	
		# The [Mount] field:
			{
				[Mount]

				What=/var/lib/snapd/snaps/core_6673.snap
				
				Where=/snap/core/6673
				
				Type=squashfs
				
				Options=nodev,ro,x-gdu.hide
			}
			Field 		Purpose
			What 		The file to be mounted including its path. Note that an absolute path must be used in the name of the mount unit which it controls.
			Where 		The location it will be mounted to.
			Type 		The filesystem type that the file is stored in. In the example above, this is squashfs, the compressed, read-only filesystem.
			Options 	Defines the specific options to be used. The nodev option is a security feature that prevents block special devices (which could allow harmful code to be run) from being mounted on the filesystem. The ro option stands for read-only and the x-gdu.hide option prevents the snap mount from being visible to System Monitor.
	
		# The [Install] field:
			{
				[Install]

				WantedBy=multi-user.target
			}
			Field 			Purpose
			WantedBy 		Tells systemd that this filesystem is to be used by the multi-user boot target.
	
		# Although mount unit configuration does allow for more flexible mounting of resources. One case for network resources would be where having the ability to define things like how long to wait for the mount command to finish, is desirable. However, in many cases, using the fstab file is still the preferred approach.
	}

	21.8 loop Option{
		# The loop option to the mount command is used to mount special filesystems that are stored within a file. These files have the extension of .img or .iso (for ISO 9660 filesystem files), which contain complete filesystems that can be mounted with the mount command by using the loop option:
		in terminal{
			root@localhost:~# mount -o loop fs.img /mnt

			# or 

			root@localhost:~# mount -o loop cdrom.iso /mnt
		}

		# To better understand the purpose of the loop option, consider the following scenario: A system administrator has been instructed to download an ISO file software.iso from the internet. This ISO file contains several RPM software packages that need to be installed on some local systems. The administrator has two choices, burn a DVD of the ISO file, or to mount the ISO file as part of the filesystem. To conserve resources, the administrator chooses to mount the ISO file.

		# To gain access to these software packages, which all end with the .rpm extension, the system administrator mounts the ISO file and then copies the software packages by executing the following commands:
		in terminal{
			root@localhost:~# mount -o loop software.iso /mnt
			root@localhost:~# mkdir /root/latestrpms
			root@localhost:~# cp /mnt/*.rpm /root
		}

		# After copying the software packages to the /root/latestrpms directory, the software.iso file can be unmounted and deleted from the system.

		Note{
			## Almost everything in Linux is a file, including optical disks. If there is an image of a disk inside a file, it can be mounted directly from the file without needing to burn the image back on a disk using the loop option.
		}
	}

	21.9 Monitoring Filesystems{
		### ## The df command can also be used to view mounted filesystems. The output of this command displays the usage of the filesystem, where it's mounted, and the space usage of the device. To have the df command display filesystem sizes in human-readable format, use the -h option. Use the -T option to have the df command display the filesystem type:
		in terminal{
			root@localhost:~# df -hT
			Filesystem    Type    Size  Used Avail Use% Mounted on
			/dev/sda2     ext4    6.3G  3.2G  2.9G  53% /
			tmpfs        tmpfs    351M   84K  351M   1% /dev/shm
			/dev/sda1     ext4    485M   52M  408M  12% /boot
			/dev/sda5     ext4    2.2G   69M  2.0G   4% /home
		}

		# The output displays the filesystems that have variable free space; the tmpfs filesystem, which is similar to a RAM disk, falls into this category, while other pseudo-filesystems like the proc filesystem, do not.
	}

	21.10 Mount a Filesystem{
		# The following describes how to configure a new filesystem that has been created on the /dev/sdb1 device to mount during the boot process automatically. One single line will be added at the end of the /etc/fstab file. The assumption for this example is that the partition has been created by the fdisk command and the filesystem has been created by the mkfs command.

		# Before modifying the /etc/fstab file, first, gather the information needed. Use the blkid command to determine the UUID or label of the new filesystem. The result will be similar to the following:
		in terminal{
			root@localhost:~# blkid dev/sdb1
			/dev/sdb1: UUID="a9183c2c-ee1f-4e57-9a60-b0d9e87a0337" TYPE="ext4" LABEL="mydata"
		}
		# Next, create a mount point in the existing tree with the mkdir command:
		in terminal{
			root@localhost:~# mkdir /data
		}

		# In this example, the filesystem label will be used. So, the first field should be:
			LABEL="mydata"
			-------------
		# Now, place the following as the second field:
			LABEL="mydata" /data
							-----
		# Assuming the filesystem on the partition is the Fourth Extended type, the value for the third field will be:
			LABEL="mydata" /data ext4
									----
		# Unless there is a compelling reason not to do so, use the defaults for the mount options field by specifying the value for the fourth field as:
			LABEL="mydata" /data ext4 defaults
										--------
		# Since /dev/sdb1 is formatted as an ext4 filesystem and this device is local to the system, the fifth field (the dump check) should be enabled with the value of:
			LABEL="mydata" /data ext4 defaults 1
												-
		# By the same logic, the sixth field should have the value:
			LABEL="mydata" /data ext4 defaults 1 2
													-
											

		# Putting all of these fields together for the normal entry into the /etc/fstab file results in the following line:
			LABEL="mydata"  	/data 			ext4			defaults		1			2
			Device 				Mount Point 	Filesystem 		Options 		dump 		fsck

		# After modifying the /etc/fstab file, check that the new line has been added correctly by mounting the filesystem with only the mount point or device name as an argument:
		in terminal{
				root@localhost:~# mount /data

				root@localhost:~# mount /dev/sdb1
		}
	}

	21.11 Activate Swap Space{
		# The following describes how to configure a new swap partition that has been created on the /dev/sdb2 device to activate during the boot process automatically. One single line will be added at the end of the /etc/fstab file. The assumption here is that the partition has been created by the fdisk command and the partition has been configured as a swap partition with the mkswap command.

		# For the first field, specify the device. Again, use the blkid command to gather the information about this partition. The output would look something like the following:
		in terminal{
			root@localhost:~# blkid /dev/sdb2
			/dev/sdb2: UUID="6f450a83-9d2e-409f-8bce-826696a49e54" TYPE="swap" LABEL="myswap"
		}

		# In this example, the swap label will be used. So, the first field should be:
			LABEL="myswap"
			--------------

		!!! # When creating an entry for a swap file instead of a swap partition, always use the path name for the swap file, such as /root/swapfile. This is the only setting in the /etc/fstab entry that will be different for a swap file than a swap partition.

		# For the mount point in the second field, all swap partitions always use the following:
			LABEL="myswap" swap
							----

		# For the filesystem type in the third field, all swap partitions always use the following:
			LABEL="myswap" swap swap
								----
		
		# The defaults mount option can be used with swap partitions or swap files, just as it can be used with regular filesystems. In most cases, using defaults is fine for performance if all swap devices are equal in read/write performance; for this example, the defaults option will work well for the value of the fourth field:
			LABEL="myswap" swap swap defaults
										--------
		
		# The fifth and sixth fields, the dump check and filesystem check fields, are never enabled for either swap partitions or swap files, so they should both be zero:
			LABEL="myswap" swap swap defaults 0 0
												---

		# Putting all of these fields together for the normal swap partition into the /etc/fstab file results in the following line:
			LABEL="myswap"		swap			swap			defaults		0		0
			Device 				Mount Point 	Filesystem 		Options 		dump 	fsck
	
		### ## To verify that the swap partition or file has been added correctly, use the swapon -a command; this will activate all swap entries in the /etc/fstab file. Errors about not being able to activate spaces that were already active can be ignored, but errors in trying to activate the new swap space must be corrected in the /etc/fstab file before rebooting, or there may be issues later.

		### # After using the swapon -a command, verify that the swap partition or file is now activated by using the swapon -s command. If the output includes the new swap partition, then the entry should be correct in the /etc/fstab file.

		# As mentioned previously, the only difference in a line that describes a swap partition versus a swap file is the first field:
			/var/swapfile		swap			swap			defaults		0		0
			Device 				Mount Point 	Filesystem 		Options 		dump 	fsck
	}

	key terms{
		/etc/fstab
			A file that contains descriptive information about various file systems. The filesystems described in this file will eventually be mounted by the mount command either manually or when the system is booted.
			Section 21.5 | Section 21.6 | Section 21.10 | Section 21.11 
		/media/
			The directory containing subdirectories used as mount points for removable media such as floppy disks, cdroms, dvds, and flash drives.
			Section 21.3 
		blkid
			Command that can be used to determine the UUID value for a device.
			Section 21.5 
		fsck
			Command used to check and optionally repair one or more Linux file systems. If no filesystem is specified with the command, fsck will check all filesystems in the /etc/fstab file by default.
			Section 21.5 
		lsblk
			Command that lists information about block devices.
			Section 21.2 
		mount
			Command used to tell the Linux kernel to attach a files system found on a device to a certain directory.
			Section 21.2 | Section 21.3 | Section 21.5 | Section 21.6 | Section 21.7 | Section 21.8 | Section 21.10 
		umount
			Command used to tell the Linux kernel to detach a file system found on a device from a certain directory.
			Section 21.3 | Section 21.4 
	}
}


Chapter 22: Maintaining the integrity{
	in class{
		1- to maintain the intergrity of filesystem you need to monitor it

		- you need to monitor the data block space and free inodes.

		- df command will display filesystem usage

			df -h

			df -s

			df -i

		- du command shows the file size 

			du | sort -n

			du | sort -n | tail -10

			du -h //human readable output

			du -sh /bin /usr/bin



		2- most common causes of filesystem damage is:

			- shuting down the system improperly. init 0 init 6 systemctl poweroff

												systemctl reboot


		When a partition or disk is formatted, the sectors in the hardisk is first divided into small groups. 

		This groups of sectors is called as blocks. The block size is something that can be specified when a user formats a partition using the command line parameters available	
	}

	me read{
		22.2 Filesystem Issues{
			!!! # Before discussing filesystem utilities in depth, it is important to discuss the most common causes of filesystem damage. For example, one of the easiest ways to damage a filesystem is to shut down the system improperly. You should never just flip the switch on a surge suppressor or pull the plug from its power source unless the system will not respond to all other attempts to shut it down properly. In many cases, just pressing the power button once will cause many systems to shut down gracefully (this depends on the hardware and BIOS settings of the computer).

			# There are also a few commands available to shut down the Linux system from the command line. For example, the following init commands and user commands are available. 
				Init Command 		Purpose 					User Command
				init 0 				Shut the system off 		halt
				init 6 				Restart the system 			reboot
			
			# Be aware that the init commands require root privileges, whereas the user commands do not if the user is logged in locally and there are no other users logged into the system. Also, discretion is recommended when using the init command as it is abrupt and can cause unintended consequences. In some cases, it is considered more appropriate to use the shutdown -h, shutdown -r, poweroff, or even reboot commands, many of which are links to each other. 
		}

		22.3 Monitoring Disk Info{
			# Two storage-related statistics that should be monitored closely to ensure a system will continue to run correctly are free data block space and free inodes. The df command can help monitor both of these important numbers. 

			# By default, the df command without any option or arguments will display filesystems usage using 1K (1024 bytes) data block size:
			in terminal{
				sysadmin@localhost:~$ df
				Filesystem     1K-blocks       	Used	Available Use%  Mounted on
				overlay       3711914792   119199908  3404137348    4%  /
				tmpfs         	66007320           0  	66007320    0%  /dev
				tmpfs         	66007320           0  	66007320    0%  /sys/fs/cgroup
				/dev/sda2     3711914792   119199908  3404137348    4%  /etc/hosts
				shm                65536           0       65536    0%  /dev/shm
			}

			### # When executed with the -h option, the output of the df command is displayed in human-readable units such as MiB and GiB:
			in terminal{
				sysadmin@localhost:~$ df  -h
				Filesystem    	Size  Used Avail Use% Mounted on
				overlay       	3.5T  114G  3.2T   4% /
				tmpfs            63G     0   63G   0% /dev
				tmpfs            63G     0   63G   0% /sys/fs/cgroup
				/dev/sda2       3.5T  114G  3.2T   4% /etc/hosts
				shm              64M  	 0   64M   0% /dev/shm
			}

			### # Additional options will yield even more interesting and helpful information, try adding a -T to the df command to see the filesystem Type added as a column to the output:
			in terminal{
				sysadmin@localhost:~$ df -hT
				Filesystem 	Type     Size  Used Avail Use% Mounted on
				overlay    	overlay  3.5T  114G  3.2T   4% /
				tmpfs      	tmpfs 	  63G     0   63G   0% /dev
				tmpfs      	tmpfs 	  63G     0   63G   0% /sys/fs/cgroup
				/dev/sda2  	ext4     3.5T  114G  3.2T   4% /etc/hosts
				shm        	tmpfs 	  64M     0   64M   0% /dev/shm
			}

			# Each file created in a filesystem is assigned a unique identifier by the filesystem. This identifier is known as an inode and there is a fixed number of them available when using ext2/ext3/ext4.In other words, if a filesystem has only 10,000 inodes, only 10,000 files can be stored in that filesystem.

			### # To determine how many files have been created and how many inodes are still available for a filesystem, use the -i option to the df command:
			in terminal{
				sysadmin@localhost:~$ df -i
				Filesystem    	Inodes     IUsed     IFree IUse% Mounted on
				overlay    	235708416 502951 235205465    1% /
				tmpfs       	16501830      19  16501811    1% /dev
				tmpfs       	16501830      14  16501816    1% /sys/fs/cgroup
				/dev/sda2  	235708416 502951 235205465    1% /etc/hosts
				shm         	16501830       1  16501829    1% /dev/shm
			}

			# The number of inodes is determined when the filesystem is created. The default technique is to use a ratio that depends on how many data blocks the filesystem contains, so larger filesystems will contain more inodes. The options that can be used to affect this ratio will be discussed later.

			# Be sure to view the output of the df command carefully to find filesystems that are getting low on data block space or inodes. If a filesystem is getting low, take steps like moving some files to another filesystem with more resources or removing files that are unnecessary.
		}

		22.4 The du Command{
			# The directory usage du command will report the size of files and directories'; this can be helpful for finding the largest ones:

			# The default output of the du command shows just two columns of information: the file size and the path name for the file. The du command is automatically recursive, so it will normally process not only the current directory but also all of its directories.

			# An effective way to find the largest files within the specified directories is to pipe the output to the sort command with the -n option, so that the output will be sorted from smallest to largest. For example, executing the du | sort -n command in a user's home directory would result in output like the following, placing the largest files at the bottom of the output:
			in terminal{
				sysadmin@localhost:~$ du  | sort  -n  | tail  -10
				4   	./Pictures
				4   	./Public
				4   	./Templates
				4   	./Videos
				8   	./Documents/School/Art
				8   	./Documents/School/Engineering
				8   	./Documents/School/Math
				28  	./Documents/School
				1128	./Documents
				1180	.
			}

			!!!! Keep in mind that errors will likely result if the du command is run outside of a regular user's own home directory or the /tmp and /var/tmp directories.

			### Two options used often with the du command are the human-readable -h option and the summary -s option to only display a summary of the entire directory. For example, executing the command below would display a human-readable summary of how much space is used by both the /bin and the /usr/bin directory.
			in terminal{
				sysadmin@localhost:~$ du -sh /bin /user/bin
				6.6M	/bin
				38M 	/usr/bin
			}

			### # To limit the depth of how recursive the du command will be, provide a numerical argument to the --max-depth option to indicate how many directories deep to display.
			in terminal{
				sysadmin@localhost:~$ du Documents
				8       Documents/School/Math
				8       Documents/School/Engineering
				8       Documents/School/Art
				28      Documents/School
				4       Documents/Work
				1128    Documents
				sysadmin@localhost:~$ du --max-depth=1 Documents
				28      Documents/School
				4       Documents/Work
				1128    Documents
			}

			### # If there are files or directories that shouldn't be included, use one or more --exclude options. Glob characters can be used as well to form the pattern to be used by the --exclude option.
			in terminal{
				sysadmin@localhost:~$ du --exclude=School Documents
				4       Documents/Work
				1100    Documents
			}

			# As an example of using these both options, analyze the output of the du command in the following example. To determine the size of each directory that is a direct child of the /usr directory, the --max-depth=1 option is used.

			# The following command will be run as a regular user, which means accessing the /usr/lib/audit directory will result in an error as regular users do not have access to this directory. The --exclude=/usr/lib/audit option avoids this error
			in terminal{
				sysadmin@localhost:~$ du -h --max-depth=1 --exclude=/usr/lib/audit
				4.0K	./Public
				4.0K	./Downloads
				4.0K	./Pictures
				4.0K	./Videos
				4.0K	./Templates
				4.0K	./Desktop
				4.0K	./Music
				1.2M	./Documents
				4.0K	./.cache
				1.2M	.
			}
		}

		22.5 The tune2fs Command{
			# The tune2fs command can view and change some of the settings for ext2, ext3, and ext4 filesystems. Generally, this command is considered safe, but to avoid taking risks, a backup of the filesystem should be made before using the command.

			# The tune2fs command has a number of options. Below are a few examples of common options that can be used on a filesystem.

			# By default, each filesystem will have a full system check during the boot process either every 180 days or after 30 mounts, whichever comes first. Unfortunately, this slows the boot process, especially if all filesystems are checked during a single boot. Automatic filesystem checking can be disabled by executing the following:
			in terminal{
				root@localhost:~# tune2fs -c0 -i0 /dev/sdb1
			}

			### # In the example above, the -c option will change the maximum number of times that a filesystem may be mounted before it is required to have a full filesystem check. The default value of 30 times has been disabled by setting the value to 0. The -i option will change the maximum time interval between when a filesystem is forced to have a full filesystem check. This default value of 180 days has been disabled by setting the interval to 0.

			# To automatically have the acl and user_xattr mount options apply any time filesystem is mounted, execute the following command:
			in terminal{
				root@localhost:~# tune2fs -o acl,user_xattr /dev/sdb1
			}

			### The -o option in the command above specifies the default mount options. By default, the Red Hat derived distributions specify that acl and user_xattr options are added to filesystems created during installation. Note that when applying multiple options, they need to be comma separated.

			### Finally, to verify the changes have been saved, list the superblock information for the filesystem by using the -1 option:
			in terminal{
				root@localhost:~# tune2fs -1 /dev/sdb1
			}

			# To summarize, the following is a table of options available for tune2fsto tune a ext2, ext3 or ext4 filesystem:
				Option 		Effect
				-l			List the superblock information for a filesystem.
				-c 			Change the maximum number of times that a filesystem may be mounted before it is required to have a full filesystem check. The default value is normally 30 times. This can be disabled by setting the value to 0.
				-i 			Change the maximum time interval between when a filesystem is forced to have a full filesystem check. The default value is 180, meaning 180 days. This can be disabled by setting the interval to 0.
				-j 			Create a journal file for an ext2 filesystem, allowing it to be mounted as an ext3 or ext2 filesystem.
				-m 			Specify the percentage of space to be reserved for the root user or privileged processes. The default value of 5% is often unnecessarily large for large filesystems.
				-o 			Specify default mount options. By default, the RedHat derived distributions specify that acl and user_xattroptions are added to filesystems created during installation. When applying multiple options, they need to be comma separated.
				-b 			Allows the block size to be specified. Valid block sizes are 1024, 2048, or 4096 bytes (some systems allow a block size of 8192). If the "wrong" block size is used, the filesystem may run out of data blocks before running out of inodes. If the average file size is smaller than 4 KiB, it may be beneficial to use a smaller block size closer to the average file size.
				-I 			Allows the size of an inode to be specified. By default, mke2fs will make an inode size of 128 bytes. If the system uses SELinux or SambaV4, it may be beneficial to set this size to 256 bytes to allow space extended attributes that SELinux and sambaV4 use.
				-i 			Allows a bytes/inode ratio to be specified. To avoid either running out of data blocks while still having inodes, or vice versa, set a ratio that will be close to the average file size. As each file requires at least one inode to store its meta-information, this is a critical value.
				-N 			If the size of the average file is unknown, but the number of files required is known, use this option to specify exactly how many inodes to create
		}

		key terms{
		
			df
				Command used to report file system disk space usage. df can be used with a FILE name agrument, if no FILE name is given, the sapce available on all urrently mounted file systems will be reported.
				Section 22.3 
			du
				Command used to estimate file usage on a disk. du will summarize disk usage of each FILE, recursively for directories.
				Section 22.4 
			tune2fs
				Command that allows a system administrator to adjust various tunable file system parameters such as mount count and maximum mount counts before a file system check needs completed. tune2fs works with the ext2/3/4 family of file systems.
				Section 22.5 
		}
		
	}
}

Chapter 23: Fixing File system with fsck{

	in class{
		1- you need to backup your files regularly 

		2- Power outages may also cause file corruption, that is way somtimes we need UPSs on 

			critical systems
		
		So to check the filesystem use fsck command

		-fsck is the front end of back end command like e2fsck 

		man fsck.vfat

		man fsck.ext4 lead to e2fsck
		
		- it is not importent to know what back end command to use simply use fsck

		fsck <path>
		
		- If fsck command runs on the monted filesystem the following error will apear


		fsck -y //yes to all options

		fsck -f //force the check the filesystem


		dumpe2fs /dev/sdb1 | grep superblock

		e2fsck -b <number> /dev/sdb1

		clearman 
		
		3 lost+found Directory

		if the fsck produces any unreferenced file errors, you need to check the lost+found directory

		ls -l /dev/sdb1/lost+found
		
		file command can be used to determine the type of file, and view the contents.
	}

	me read{
		23.2 The fsck Command{
			## The fsck command is used to check filesystems for consistency issues and to repair those issues when found. The fsck command has some similarities to the mkfs command. First of all, it is a generic tool for use with filesystems; its purpose is to check filesystems for errors and attempt to repair them. Second, fsck is actually a front end for the various filesystem checkers, meaning it will call the appropriate back end command, like the e2fsck command, based upon the filesystem type.

			# The files that link the front end to the back end are named by patterns like the fsck.FILESYSTEM-TYPE pattern, such as fsck.ext4 or fsck.vfat. These files between the front and back end commands can be a great way to find documentation.

			## For example, to discover the actual filesystem-specific command that is used to check vfat filesystems, execute the man fsck.vfat command. This will display the man page for the real back end command for checking vfat filesystems, which is the dosfsck command. Likewise, viewing the man page for fsck.ext4 displays the e2fsck command used for checking ext2, ext3, and ext4 filesystems.

			### # It is not necessary to know which back end to use. Simply execute the fsck command with either the pathname for the filesystem or its mount point. The fsck command will determine the filesystem-specific program to call based upon the filesystem type from the entry in the /etc/fstab file. If the filesystem does not have an entry in the /etc/fstab file, then the -t option can be used with the fsck command to specify the filesystem type.

			!!!! Warnings About the fsck Command{
				# While this tool is designed to check and fix filesystems, it can actually damage filesystems too! The fsck utility is not designed to be executed on currently used filesystems (systems that are already mounted). If the fsck command is run on a currently mounted filesystem, the following error will appear:
				in terminal{
					root@localhost:~# fsck /dev/sda1
					fsck from util-linux-ng 2.17.2


					e2fsck 1.41.12 (17-May-2010)
					/dev/sda1 is mounted.


					WARNING!!  The filesystem is mounted.   If you continue you ***WILL*** cause ***SEVERE*** filesystem damage.


					Do you really want to continue (y/n)? no
					check aborted
				}
				# In this case, definitely type n for no. Keep in mind, if the filesystem is already mounted, then it doesn't need to be checked. The very fact that it is mounted means it is working correctly.

				Consider This{
					# When it comes to backups, late may be better than never. If a filesystem is damaged and can't be mounted, consider making a backup of it with the dd command before trying to fix it with the fsck command. That way, if the fix that the fsck command performs actually makes things worse than they were originally, it is still possible to revert back to the condition preserved in the backup.
				}

				### One of the more useful options for the fsck command is the -y option, which will cause fsck to assume a yes response to all prompts that it would normally make. Using this option may prevent hours typing the letter y in response to questions from the tool like, Would you like to fix this?
			
				# Another non-interactive approach is to force a filesystem check to occur, by executing the touch /forcefsck command as the root user. If this file exists at boot time, then the fsck command is executed on all filesystems in the /etc/fstab file that have a non-zero value for the FSCK column. After completion, the /forcefsck file will be removed, and the timestamp of the /.autofsck file will be updated to the time when the check finished.

				# For partitions that can be unmounted while the system is running, the fsck command can be started interactively to perform the check. For example:
				in terminal{
					root@localhost:~# mount | grep /data
					/dev/sdb1 on /data type ext4 (rw)
					root@localhost:~# umount /data
					root@localhost:~# fsck /dev/sdb1
					fsck from util-linux-ng 2.17.2
					e2fsck 1.41.12 (17-May-2010)
					/dev/sdb1: clean, 11/12824 files, 6532/51200 blocks
				}

				# Note that the fsck command did not perform a filesystem check in the previous example. Since the filesystem was cleanly unmounted (which would also happen during a normal system shutdown or reboot), the state of the filesystem was set to clean. The fsck command doesn't perform any checks when the filesystem state is clean.

				### # A filesystem check can be forced by using the -f option:
				in terminal{
					root@localhost:~# fsck -f /dev/sdb1
					fsck from util-linux-ng 2.17.2
					e2fsck 1.41.12 (17-May-2010)
					Pass 1: Checking indoors, blocks, and sizes
					Pass 2: Checking directory structure
					Pass 3: Checking directory connectivity
					Pass 4: Checking reference counts
					Pass 5: Checking group summary information
					/dev/sdb1: 11/12824 files (9.1% non-contiguous), 6532/51200 blocks
				}

				# When a partition has a problem, attempting to mount it may result in an error message like this:
				{
					mount: you must specify the filesystem type
				}

				# Normally, the mount command will read the first block of the filesystem (the superblock) where the information about the filesystem type is kept. When a superblock is damaged, the mount command is unable to read that information.

				# In this case, use the fsck command to fix the filesystem. The output may look something like the following:
				{
					fsck from util-linux-ng 2.17.2

					e2fsck 1.41.12 (17-May-2010)

					fsck.ext2: Superblock invalid, trying backup blocks...
					mydata was not cleanly unmounted, check forced.
					Pass 1: Checking inodes, blocks, and sizes
					Pass 2: Checking directory structure
					Pass 3: Checking directory connectivity
					Pass 4: Checking reference counts
					Pass 5: Checking group summary information

					mydata: ***** FILE SYSTEM WAS MODIFIED *****
					mydata: 11/25688 files (0.0% non-contiguous), 4800/102400 blocks
				}
				# Notice the highlighted text of the output shows that the command tried backup blocks. The fsck command will often be able to find a backup copy of the superblock that was created at the time the filesystem was last modified.
			}
		}

		23.3 The e2fsck Command{
			# The e2fsck command is the filesystem checker called by fsck for ext2, ext3, and ext4 filesystems. There are options that can be used with the e2fsck command that aren't documented in the man page for the fsck command. These filesystem-specific options can be used directly with the e2fsck command or with the fsck command (which will pass the options to thee2fsck command).

			## For example, the fsck command may require the exact location of a backup superblock. The superblock is a critical component to the filesystem, and when corrupted, it is difficult to recover. The backup superblocks are used by the fsck command to fix a corrupted superblock.

			# If custom settings were used when creating a filesystem, the backup superblocks may not be in a standard location. In that case, the output of the mkfs command should be documented because that output includes the location of the backup superblocks. These backup superblocks may be located by using the dumpe2fs command:
			in terminal ( The following examples may not match the output | output can be different ) {
				root@localhost:~# dumpe2fs /dev/sdb1 | grep superblock
				dumpe2fs 1.41.12 (17-May-2010)
					Primary superblock at 1, Group descriptors at 2-2
					Backup superblock at 8193, Group descriptors at 8194-8194
					Backup superblock at 24577, Group descriptors at 24578-24578
					Backup superblock at 40961, Group descriptors at 40962-40962
			}

			### # Use the -b option with the e2fsck command to specify a backup when the primary superblock has been corrupted. For example:
			in terminal{
				root@localhost:~# e2fsck -b 8193 /dev/sdb1
			}

			# The fsck command could also be used with the same option, as it will pass this option on to the e2fsck command:
			in terminal{
				root@localhost:~# fsck -b 8193 /dev/sdb1
			}

			# There are a couple of other options to automate the e2fsck command. The -n option assumes that the input for every prompt is no. The -n option can be useful when running the command to test for possible problems, but opting not to fix them at this time. The output can be captured for further analysis and discussion, perhaps with another administrator.
		}

		23.4 The lost+found Directory{
			# In most cases, after running the fsck command, the fixed filesystem is mounted and no further action is required. However, if the fsck command produces any unreferenced file errors, it may be prudent to look inside the lost+found directory that is located in the mount point directory of the filesystem. This is the location where all lost files are stored.

			# A file can be “lost” if its filename becomes corrupted and therefore cannot be placed in a normal directory. After fsck, such a file is relocated to the lost+found directory, and its inode number will appear instead of the filename.

			in terminal ( The following examples may not match the output | output can be different ) {
				root@localhost:~# ls -l /data
				lost+found
				root@localhost:~# ls -l /data/lost+found
				total 5
				-rw-r--r--. 1 root root   83 Mar  4 06:37 #34234
				-rw-r--r--. 1 root root 1911 May 20  2013 #4596
			}

			# What should be done with these “poor, lost files”? Without a name, it may be hard to find where they belong, but keep in mind that the file command can be used to determine the file type. For text files, viewing the contents may be helpful. The files’ timestamps and ownership can also help to determine where these files belong.
		}

		23.5 Repairing XFS Filesystems{
			# XFS filesystems are repaired differently than other file systems. As XFS is capable of containing immensely large numbers of files (inodes), which would make boot-time checking impractical, even using a file system journal, which XFS does.

			# XFS relies on the journal for most error correction, or when dealing with the filesystem being marked as not having been properly unmounted. If a filesystem is not cleanly unmounted, it is marked as needing to be checked, which XFS does by replaying the journal log—usually this is enough to ensure that the data is written correctly.

			# In cases where XFS’s metadata or structure has become corrupted, an error such as mount: Structure needs cleaning may occur, and the xfs_repair utility will need to be run against the filesystem in order to repair any inconsistencies.

			Consider This{
				Whenever a filesystem is apparently corrupted, it’s best to have a backup of the data on the filesystem. The xfs_copy and xfsdump commands may be helpful in that regard. The xfs_copy command can create an exact duplicate of the questionable filesystem in order to experiment with repairs.

				These commands are out of the scope of the objectives and of this course.
			}

			# In the eventuality that you must attempt the repair an XFS filesystem, it’s fairly straightforward to use. The xfs_repair command can only be run on an unmounted filesystem, which means if the XFS filesystem on a device is used as the /home directory, then all users must be off the filesystem in order to unmount it for repair.

			# To unmount the /dev/sda3 filesystem, as the root user (and not in the /home directory structure) use the command:
			in terminal  ( The following examples may not match the output | output can be different ) {
				root@localhost:~# umount /dev/sda3
			}
			# To use xfs_repair on the filesystem, use the following command:
			in terminal  ( The following examples may not match the output | output can be different ) {
				root@localhost:~# xfs_repair /dev/sda3

				Phase 1 - find and verify superblock...
				Phase 2 - using internal log
						- zero log...
						- scan filesystem freespace and inode maps...
						- found root inode chunk
				Phase 3 - for each AG...
						- scan and clear agi unlinked lists...
						- process known inodes and perform inode discovery...
						- agno = 0
						- agno = 1
						- agno = 2
						- agno = 3
						- process newly discovered inodes...
				Phase 4 - check for duplicate blocks...
						- setting up duplicate extent list...
						- check for inodes claiming duplicate blocks...
						- agno = 0
						- agno = 1
						- agno = 2
						- agno = 3
				Phase 5 - rebuild AG headers and trees...
						- reset superblock...
				Phase 6 - check inode connectivity...
						- resetting contents of realtime bitmap and summary inodes
						- traversing filesystem ...
						- traversal finished ...
						- moving disconnected inodes to lost+found ...
				Phase 7 - verify and correct link counts...
				done
			}

			Note{
				# In certain circumstances, it may be advantageous to zero out the XFS filesystem’s journal log, such as when the journal log has become corrupted. Zeroing out an XFS journal log is an extreme move, and should only be done as a last resort.

				# To zero out an XFS filesystem’s journal log, use the command:
				in terminal{
					root@localhost:~# xfs_repair -L /dev/sda3
				}
			}

			# In situations where manual repair of the XFS filesystem is desired, the xfs_db command can be used to initiate such repair on an XFS filesystem. The xfs_db command is used to perform debugging options and possible repairs to an XFS filesystem, but if inexpertly used can easily make the filesystem unusable and unrecoverable.

			To use xfs_db in expert mode use the command:
			in terminal{
				root@localhost:~# xfs_db -x /dev/sda3
			}

			!!! Expert mode of the xfs_db command allows for the modification of data structures, which can be dangerous!
			
			# As a method of keeping your XFS filesystems in good shape, the xfs_fsr or Filesystem Reorganizer for the xfs command can be used on your mounted XFS filesystems to keep them organized and working well.

			# Before invoking the xfs_fsr command to use system resources reorganizing filesystems, it’s a good idea to check if they need this sort of maintenance. The xfs_db command can be used to assess the need for reorganization:
			in terminal{
				root@localhost:~# xfs_db -r /dev/sda3
				xfs_db>frag
				actual 345, ideal 289, fragmentation factor 16.23%
				Note, this number is largely meaningless.
				Files on this filesystem average 1.19 extents per file
				xfs_db>quit
			}

			# To reorganize and optimize all mounted filesystems on your system and see verbose output on exactly what is being done to what files, use the command:
			in terminal{
				root@localhost:~# xfs_fsr -v /dev/sda3
				No improvement will be made (skipping): ino=3147588472
				ino=1247877226
				No improvement will be made (skipping): ino=1247877226
				ino=124787727
				No improvement will be made (skipping): ino=1247877440
				ino=1247877470
				extents before:2 after:1 DONE ino=1247877470
				ino=1247849901
				extents before:2 after:1 DONE ino=1247849901
				ino=1247849973
				No improvement will be made (skipping): ino=1247849973
				ino=1247877640
				Output Omitted...
			}

			# Another very useful feature of the xfs_fsr command is that you can set it to run for a given period of time, so it can be started either manually or on a scheduled basis to run for a couple of hours each night when the system is less utilized. To run xfs_fsr for 1 hour and then stop:
			in terminal{
				root@localhost:~# xfs_fsr -t 3600
			}

			# The utility will then go to work for up to an hour, reorganizing the drives file by file until the time limit is over, or the files are done being reorganized.

			# If for some reason xfs_fsr is interrupted or needs to be stopped, it keeps track of where it was in the reorganization process, and can resume where it left off when it is run again.
		}

		key terms{
			e2fsck
				Command used to check the ext2/ext3/ext4 family of file systems.
				Section 23.3 
			fsck
				Command used to check and optionally repair one or more Linux file systems. If no filesystem is specified with the command, fsck will check all filesystems in the /etc/fstab file by default.
				| Section 23.2 
			xfs_db
				Command that can be used to perform debugging options and possible repairs to an XFS filesystem.
				Section 23.5 
			xfs_fsr
				Filesystem Reorganizer for the <command>xfs</command> command can be used on your mounted XFS filesystems to keep them organized and working well.
				Section 23.5 
			xfs_repair
				A utility that can be run in order to repair any inconsistencies in a filesystem. The <command>xfs_repair</command> command can only be run on an unmounted filesystem
				Section 23.5 
		}
	}
}

Chapter 24: Package Management{
	24.2 RPM Package Management{
		# Red Hat's package management system is based upon the file format used to package the software files used within that distribution, known as the RPM Package Manager. Although invented at Red Hat, RPM is used for managing software for many different distributions and is the baseline software management system defined by the Linux Standards Base.

		## RPM files are available in two formats: .src.rpm files and .rpm files. Unless you are compiling the software yourself or viewing the source code of the software, you don't need to be concerned with the .src.rpm files. These files contain the source code that is used to build the binary .rpm files. The binary .rpm files are the ones that contain the compiled code that is ready to use.

		# The files that are used by RPM have a specific naming convention to help identify the package, its version number, its release identifier, and which architecture the software was built for. For example, if a file was named:
		{
			x3270-x11-3.3.6-10.5.el6.i686.rpm

			# Then critical information could be discovered from just the file name:

			package_name-version-release.architecture.rpm
		}

		Package Name{
			x3270-x11-3.3.6-10.5.el6.i686.rpm
			---------

			# The name of the package may include a hyphen. The name ends where the version number begins; the version number is always a decimal delimited number.
		}

		Version Number{
			x3270-x11-3.3.6-10.5.el6.i686.rpm
					  -----

			# Immediately following the package name and the hyphen that follows the package name is the version number. This version number is set by the original developer of the software.
		}

		Realize Identifier{
			x3270-x11-3.3.6-10.5.el6.i686.rpm
							--------
			
			# Following the hyphen after the version number is the release identifier. Release identifiers are chosen by the packager (not the software developers) of the software, which is normally the vendor of the distribution.
		}

		Architecture{
			x3270-x11-3.3.6-10.5.el6.i686.rpm
									 ----
			
			# If a package contains binary code, then the computer architecture that the code was compiled on will be the final part of the file name before the .rpm file extension. There are several architecture types:
			{
				Code 			Architecture
				------------------------------
				noarch 			Packages that do not contain binary code, such as those that may only contain script files
				src 			Packages that have not been compiled
				i686 			Packages compiled to run in 32-bit mode on a Pentium 4 or later processor
				x86_64 			Packages compiled to run in 64-bit mode on either an AMD 64-bit processor or an Intel EM64T 64-bit compatible processor
			}
		}
	}

	24.2.1 RPM Queries{
		# Any user can perform RPM queries to display information about packages that are currently installed on the system or about RPM files that have yet to be installed (either on the filesystem or reachable by a URL). The difference between doing a query about an installed package versus an RPM file is two-fold:
		{
			### To query a package that is not installed, use the -p FILE option. The FILE argument specifies the path to a local .rpm file or URL of an .rpm file on the internet (ftp or http).

			# To query an installed package, use only the package name.
		}

		# To perform any RPM query, always use the -q option with the rpm command. To query for basic package information, use the -i option:
		in terminal{
			[sysadmin@localhost ~]$ rpm -qi bash
			Name        : bash
			Version     : 4.2.46
			Release     : 31.el7
			Architecture: x86_64
			Install Date: Tue Dec  4 14:38:13 2018
			Group       : System Environment/Shells
			Size        : 3667773
			License     : GPLv3+
			Signature   : RSA/SHA256, Mon Nov 12 14:21:49 2018, Key ID 24c6a8a7f4a80eb5
			Source RPM  : bash-4.2.46-31.el7.src.rpm
			Build Date  : Tue Oct 30 17:09:33 2018
			Build Host  : x86-01.bsys.centos.org
			Relocations : (not relocatable)
			Packager    : CentOS BuildSystem <http://bugs.centos.org>
			Vendor      : CentOS
			URL         : http://www.gnu.org/software/bash
			Summary     : The GNU Bourne Again shell
			Description :
			The GNU Bourne Again shell (Bash) is a shell or command language
			interpreter that is compatible with the Bourne shell (sh). Bash
			incorporates useful features from the Korn shell (ksh) and the C shell
			(csh). Most sh scripts can be run by bash without modification.
		}

		# To perform a similar query on the RPM file for bash, the -p option would be added along with the -q and -i options:
		in terminal{
			[sysadmin@localhost ~]$ rpm -qip bash-4.2.46-31.el7.src.rpm
		}

		!!! ### Always remember that RPM queries require the use of the -q option for installed packages and the -qp for uninstalled package files. There are many different types of queries that can be performed, as described in the following table:
		{
			Option 				Purpose
			------------------------------------------------------------------------------------------------------------------------------------------------------------------------
			-a 					List all of the installed packages currently on the system
			-c 					Display a list of configuration files that belong to the package
			-d 					List the documentation files that belong to the package
			-i 					Display the package information
			-K 					Check the package integrity
			-l 					List all files in the package
			--provides 			List the capabilities this package provides
			-R 					List the capabilities that this package requires
			--scripts 			List the scripts that are used before and after installation of the package
			-s 					Display the state of each package file as normal, not installed or replaced
		}

		Querying Scripts{
			# It is a good idea to query a package to see the scripts it will execute before installing an RPM file from a third-party source. Because root privileges are required by default to install or remove RPM packages from the system, these scripts will run as root during the installation or removal of a package from the system; this is potentially dangerous since scripts run as root can make any change to the system.

			# Before installing the x3270-x11 package, the administrator could view the scripts to ensure that they are not dangerous by executing the following command:
			in terminal{
				[sysadmin@localhost ~]$ rpm -qp --scripts x3270-x11-3.3.6-10.5.el6.i686.rpm
				postinstall scriptlet (using /bin/sh):
				cd /usr/share/x3270/fonts && /usr/bin/mkfontdir
				touch --no-create /usr/share/icons/hicolor
				if [ -x /usr/bin/gtk-update-icon-cache ]; then
				gtk-update-icon-cache -q /usr/share/icons/hicolor
				fi
				postuninstall scriptlet (using /bin/sh):
				if [ "$1" = "0" ]; then
				cd /usr/share/x3270/fonts && /usr/bin/mkfontdir
				fi
				touch --no-create /usr/share/icons/hicolor
				if [ -x /usr/bin/gtk-update-icon-cache ]; then
				gtk-update-icon-cache -q /usr/share/icons/hicolor
				fi
			}
			# The output of this query shows that there is a postinstall and postuninstall script for this package. In this case, these scripts are not dangerous, as they are updating fonts and icons that the package may use.
		}

		Querying the Integrity of a Package{
			# If an administrator is concerned with the security of the system, then not only should the administrator query a package to view its scripts, but also query the integrity of a package by using the -K option. To use this option on an .rpm file , import the public key file that is distributed by the same organization that packaged and distributed the .rpm file.

			# Typically, the public keys for the distribution are automatically included with the system. For example, on a Red Hat-derived distribution, the public key files are stored in the /etc/pki/rpm-gpg directory. An administrator can import these keys into the RPM database with the command:
			in terminal{
				[sysadmin@localhost ~]$ rpm --import /etc/pki/rpm-gpg/*
			}

			# After the keys have been imported, then a package's integrity can be verified. For example, to verify the integrity of the x3270-x11 package, an administrator could execute the following command:
			{
				[sysadmin@localhost ~]$ rpm -qpK x3270-x11-3.3.6-10.5.el6.i686.rpm
				x3270-x11-3.3-4.el7.x86_64.rpm: rsa sha1 (md5) pgp md5 OK
			}

			# Notice the only output that is capitalized is OK, meaning that the package is not corrupted. The following output has several acronyms capitalized along with NOT OK, indicating a corrupted package:
			in terminal{
				[sysadmin@localhost ~]$ rpm -qpK x3270-x11-3.3.6-10.5.el6.i686.rpm
				x3270-x11-3.3-4.el7.x86_64.rpm: rsa sha1 (MD5) PGP MD5 NOT OK
			}
		}

		Querying for Installed Packages{
			# There are several methods to determine if a package is installed. If the exact package name is known, simply query the package by name. For example, to see if the bash package is installed, execute:
			in terminal{
				[sysadmin@localhost ~]$ rpm -q bash
				bash-4.2.46-31.el7.src.rpm
			}

			# If the package is installed, then the output will be like the original RPM file name without the .rpm extension. If the package is not installed, the output will indicate so:
			in terminal{
				[sysadmin@localhost ~]$ rpm -q pickle
				package pickle is not installed
			}

			# The * glob character may be useful if the exact package name is not known. For example, if you knew that the package name contained python, but you were unsure of the rest, then execute the following command:
			in terminal{
				[sysadmin@localhost ~]$ rpm -qa *python*
				python-2.6.6-52.el6.x86_64
				python-urlgrabber-3.9.1-9.el6.noarch
				rpm-python-4.8.0-37.el6.x86_64
				python-libs-2.6.6-52.el6.x86_64
				python-pycurl-7.19.0-8.el6.x86_64
				python-iniparse-0.3.1-2.1.el6.noarch
			}

			Note{
				# To get an alphabetical list of all installed packages, execute the rpm -qa | sort command. To get a chronological list of all packages, execute the rpm -qa --last command.
			}
		}
	}

	24.2.2 Installing Packages With rpm{
		# A dependency is a software package (or a feature) that is required for another package to be installed and function correctly. When an administrator uses the rpm command to install a .rpm software package, that process will fail if the dependencies for that package are not already installed.

		# For example, to install the x3270-x11-3.3.6-10.5.el6.i686.rpm package, execute:
		in terminal{
			[sysadmin@localhost ~]$ rpm -i x3270-x11-3.3.6-10.5.el6.i686.rpm
		}

		# If there were any missing dependencies, the rpm command would fail and display an error message like the following:
		in terminal{
			[sysadmin@localhost ~]$ rpm -i x3270-x11-3.3.6-10.5.el6.i686.rpm
			error: Failed dependencies:
				libicuuc.so.42 is needed by x3270-x11-3.3.6-10.5.el6.i686
				x3270 = 3.3.6 is needed by x3270-x11-3.3.6-10.5.el6.i686
		}

		# Based upon the previous output, a library or shared object file named libicuuc.so.42 and the x3270 package (version 3.3.6) are missing. The library file is a bit tricky since it is not clear what package it belongs to. Searching the internet using the library file name reveals that the missing package needed in order to install the library file is named libicu.

		# It is important to note that sometimes a package and its dependencies must be installed at the same time if there are any circular dependencies between them. Once the x3270 and libicu packages are located, then the administrator would install them along with the x3270-x11 package by executing a command like the following:
		in terminal{
			[sysadmin@localhost ~]$ rpm -i x3270-x11-3.3.6-10.5.el6.i686.rpm x3270-3.3.6-10.5.el6.i686.rpm libicu-4.2.1-9.1.el6_2.i686.rpm
		}

		# The RPM system uses a database to track the capabilities of each previously installed package. An RPM file contains a list of package dependencies. Before installing an RPM package, the rpm command compares this information to determine if the dependencies were satisfied.

		# Most administrators determine package dependencies by examining the output of a failed RPM package install. However, it is also possible to check the requirements and dependencies of a package in advance with the following rpm query (partial output shown):
		in terminal{
			[sysadmin@localhost ~]$ rpm -qpR x3270-x11-3.3.6-10.5.el6.i686.rpm
			/bin/sh
			/usr/bin/mkfontdir
			gtk2 >= 2.6
			libICE.so.6
			libicuuc.so.42
			libnsl.so.1
			libssl.so.10
			libutil.so.1
			x3270 = 3.3.6
		}

		Note{
			To see what each package provides, perform a query with the --provides option. The output from the following command demonstrates that this package provides the required x3270 package with the version equal to 3.3.6:
			in terminal{
				[sysadmin@localhost ~]$ rpm -qp --provides x3270-3.3.6-10.5.el6.i686.rpm
				config(x3270) = 3.3.6-10.5.el6
				x3270 = 3.3.6-10.5.el6
				x3270(x86-32) = 3.3.6-10.5.el6
			}
		}

		# Occasionally, a package needs to be reinstalled, perhaps because a file from that package is missing. Normally, the rpm command will refuse to install a package that is already installed, but it can be forced by adding the --force option. For example, to reinstall the x3270 package, execute the following command:
		in terminal{
			[sysadmin@localhost ~]$ rpm --force -i x3270-3.3.6-10.5.el6.i686.rpm
		}
	}

	24.2.3 Erasing Packages with rpm{
		### The rpm command can be used to erase (remove) packages from the system with the -e option. However, dependency issues may arise. If there were dependency issues when a group of packages was installed, then there may also be dependency issues when that group of packages is removed.

		# For example, if an attempt was made to remove the x3270 or libicu packages without first removing the x3270-x11 package, then an error would occur:
		in terminal{
			[sysadmin@localhost ~]$ rpm -e x3270 libicu
			error: Failed dependencies:
				x3270 = 3.3.6 is needed by (installed) x3270-x11-3.3.6-10.5.el6.i686
					libicuuc.so.42 is needed by (installed) x3270-x11-3.3.6-10.5.el6.i686
		}

		# In other words, the rpm command will not allow a package to be erased if it is a requirement of another package. If the x3270-x11 package were erased first, then the other two packages could be erased.

		# In the case of circular dependencies, when packages depend on each other, then all the packages can be removed with a single rpm command by specifying all package names as an argument:
		in terminal{
			[sysadmin@localhost ~]$ rpm -e x3270-x11 x3270 libicu
		}
	}

	24.2.4 Updating Packages With rpm{
		# To update a package with a new version or newer release, use the rpm command with either the -U or the -F option. As was the case with installing or removing packages, dependency issues may arise when updating packages. Installing an updated package often requires the installation of updates to the packages that it depends upon.

		# The -U option can be used with the rpm command to either install or update a package:
		in terminal{
			[sysadmin@localhost ~]$ rpm -U x3270-4.3.6-10.5.el6.i686.rpm
		}

		# On the other hand, when using the rpm command with the -F option, the package will only be updated if the package is already installed; this is called freshening the package:
		in terminal{
			[sysadmin@localhost ~]$ rpm -F x3270-4.3.6-10.5.el6.i686.rpm
		}

		!!! The kernel package is so critical that when a new version is available, it should be installed rather than updated or freshened. The kernel files are organized to allow for multiple versions to exist on the system simultaneously. In this way, if an updated kernel is installed on your system but is not functional, simply reboot the system and select the previous kernel from the bootloader menu.
	}
}